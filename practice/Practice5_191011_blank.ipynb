{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practice5_191011_blank.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uL2Ctj726V-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "3ef27cdd-30d1-466d-e430-37ca2677e439"
      },
      "source": [
        "#Set google drive\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miuvX4784eux",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e0fb0fa8-64f7-45f6-c79d-24d5a7e4efcf"
      },
      "source": [
        "#Install miniconda and rdkit\n",
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!time bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!time conda install -q -y -c conda-forge rdkit\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-06 09:35:36--  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.201.79, 104.18.200.79, 2606:4700::6812:c94f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.201.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 71785000 (68M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-latest-Linux-x86_64.sh’\n",
            "\n",
            "Miniconda3-latest-L 100%[===================>]  68.46M  53.7MB/s    in 1.3s    \n",
            "\n",
            "2019-11-06 09:35:37 (53.7 MB/s) - ‘Miniconda3-latest-Linux-x86_64.sh’ saved [71785000/71785000]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - asn1crypto==1.2.0=py37_0\n",
            "    - ca-certificates==2019.10.16=0\n",
            "    - certifi==2019.9.11=py37_0\n",
            "    - cffi==1.13.0=py37h2e261b9_0\n",
            "    - chardet==3.0.4=py37_1003\n",
            "    - conda-package-handling==1.6.0=py37h7b6447c_0\n",
            "    - conda==4.7.12=py37_0\n",
            "    - cryptography==2.8=py37h1ba5d50_0\n",
            "    - idna==2.8=py37_0\n",
            "    - libedit==3.1.20181209=hc058e9b_0\n",
            "    - libffi==3.2.1=hd88cf55_4\n",
            "    - libgcc-ng==9.1.0=hdf63c60_0\n",
            "    - libstdcxx-ng==9.1.0=hdf63c60_0\n",
            "    - ncurses==6.1=he6710b0_1\n",
            "    - openssl==1.1.1d=h7b6447c_3\n",
            "    - pip==19.3.1=py37_0\n",
            "    - pycosat==0.6.3=py37h14c3975_0\n",
            "    - pycparser==2.19=py37_0\n",
            "    - pyopenssl==19.0.0=py37_0\n",
            "    - pysocks==1.7.1=py37_0\n",
            "    - python==3.7.4=h265db76_1\n",
            "    - readline==7.0=h7b6447c_5\n",
            "    - requests==2.22.0=py37_0\n",
            "    - ruamel_yaml==0.15.46=py37h14c3975_0\n",
            "    - setuptools==41.4.0=py37_0\n",
            "    - six==1.12.0=py37_0\n",
            "    - sqlite==3.30.0=h7b6447c_0\n",
            "    - tk==8.6.8=hbc83047_0\n",
            "    - tqdm==4.36.1=py_0\n",
            "    - urllib3==1.24.2=py37_0\n",
            "    - wheel==0.33.6=py37_0\n",
            "    - xz==5.2.4=h14c3975_4\n",
            "    - yaml==0.1.7=had09818_2\n",
            "    - zlib==1.2.11=h7b6447c_3\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  asn1crypto         pkgs/main/linux-64::asn1crypto-1.2.0-py37_0\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2019.10.16-0\n",
            "  certifi            pkgs/main/linux-64::certifi-2019.9.11-py37_0\n",
            "  cffi               pkgs/main/linux-64::cffi-1.13.0-py37h2e261b9_0\n",
            "  chardet            pkgs/main/linux-64::chardet-3.0.4-py37_1003\n",
            "  conda              pkgs/main/linux-64::conda-4.7.12-py37_0\n",
            "  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.6.0-py37h7b6447c_0\n",
            "  cryptography       pkgs/main/linux-64::cryptography-2.8-py37h1ba5d50_0\n",
            "  idna               pkgs/main/linux-64::idna-2.8-py37_0\n",
            "  libedit            pkgs/main/linux-64::libedit-3.1.20181209-hc058e9b_0\n",
            "  libffi             pkgs/main/linux-64::libffi-3.2.1-hd88cf55_4\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.1.0-hdf63c60_0\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.1.0-hdf63c60_0\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.1-he6710b0_1\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1d-h7b6447c_3\n",
            "  pip                pkgs/main/linux-64::pip-19.3.1-py37_0\n",
            "  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py37h14c3975_0\n",
            "  pycparser          pkgs/main/linux-64::pycparser-2.19-py37_0\n",
            "  pyopenssl          pkgs/main/linux-64::pyopenssl-19.0.0-py37_0\n",
            "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py37_0\n",
            "  python             pkgs/main/linux-64::python-3.7.4-h265db76_1\n",
            "  readline           pkgs/main/linux-64::readline-7.0-h7b6447c_5\n",
            "  requests           pkgs/main/linux-64::requests-2.22.0-py37_0\n",
            "  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.46-py37h14c3975_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-41.4.0-py37_0\n",
            "  six                pkgs/main/linux-64::six-1.12.0-py37_0\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.30.0-h7b6447c_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.8-hbc83047_0\n",
            "  tqdm               pkgs/main/noarch::tqdm-4.36.1-py_0\n",
            "  urllib3            pkgs/main/linux-64::urllib3-1.24.2-py37_0\n",
            "  wheel              pkgs/main/linux-64::wheel-0.33.6-py37_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.4-h14c3975_4\n",
            "  yaml               pkgs/main/linux-64::yaml-0.1.7-had09818_2\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3\n",
            "\n",
            "\n",
            "Preparing transaction: | \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "\n",
            "real\t0m16.439s\n",
            "user\t0m8.972s\n",
            "sys\t0m3.798s\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - rdkit\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    boost-1.70.0               |   py37h9de70de_1         337 KB  conda-forge\n",
            "    boost-cpp-1.70.0           |       h8e57a91_2        21.1 MB  conda-forge\n",
            "    bzip2-1.0.8                |       h516909a_1         397 KB  conda-forge\n",
            "    ca-certificates-2019.9.11  |       hecc5488_0         144 KB  conda-forge\n",
            "    cairo-1.16.0               |    hfb77d84_1002         1.5 MB  conda-forge\n",
            "    certifi-2019.9.11          |           py37_0         147 KB  conda-forge\n",
            "    conda-4.7.12               |           py37_0         3.0 MB  conda-forge\n",
            "    fontconfig-2.13.1          |    h86ecdb6_1001         340 KB  conda-forge\n",
            "    freetype-2.10.0            |       he983fc9_1         884 KB  conda-forge\n",
            "    gettext-0.19.8.1           |    hc5be6a0_1002         3.6 MB  conda-forge\n",
            "    glib-2.58.3                |    h6f030ca_1002         3.3 MB  conda-forge\n",
            "    icu-64.2                   |       he1b5a44_1        12.6 MB  conda-forge\n",
            "    jpeg-9c                    |    h14c3975_1001         251 KB  conda-forge\n",
            "    libblas-3.8.0              |      14_openblas          10 KB  conda-forge\n",
            "    libcblas-3.8.0             |      14_openblas          10 KB  conda-forge\n",
            "    libgfortran-ng-7.3.0       |       hdf63c60_2         1.7 MB  conda-forge\n",
            "    libiconv-1.15              |    h516909a_1005         2.0 MB  conda-forge\n",
            "    liblapack-3.8.0            |      14_openblas          10 KB  conda-forge\n",
            "    libopenblas-0.3.7          |       h6e990d7_3         7.6 MB  conda-forge\n",
            "    libpng-1.6.37              |       hed695b0_0         343 KB  conda-forge\n",
            "    libtiff-4.1.0              |       hfc65ed5_0         595 KB  conda-forge\n",
            "    libuuid-2.32.1             |    h14c3975_1000          26 KB  conda-forge\n",
            "    libxcb-1.13                |    h14c3975_1002         396 KB  conda-forge\n",
            "    libxml2-2.9.10             |       hee79883_0         1.3 MB  conda-forge\n",
            "    lz4-c-1.8.3                |    he1b5a44_1001         187 KB  conda-forge\n",
            "    numpy-1.17.3               |   py37h95a1406_0         5.1 MB  conda-forge\n",
            "    olefile-0.46               |             py_0          31 KB  conda-forge\n",
            "    pandas-0.25.3              |   py37hb3f55d8_0        11.4 MB  conda-forge\n",
            "    pcre-8.43                  |       he1b5a44_0         257 KB  conda-forge\n",
            "    pillow-6.2.0               |   py37h34e0f95_0         643 KB\n",
            "    pixman-0.38.0              |    h516909a_1003         594 KB  conda-forge\n",
            "    pthread-stubs-0.4          |    h14c3975_1001           5 KB  conda-forge\n",
            "    pycairo-1.18.2             |   py37h438ddbb_0          77 KB  conda-forge\n",
            "    python-dateutil-2.8.1      |             py_0         220 KB  conda-forge\n",
            "    pytz-2019.3                |             py_0         237 KB  conda-forge\n",
            "    rdkit-2019.03.4            |   py37hb31dc5d_1        23.3 MB  conda-forge\n",
            "    xorg-kbproto-1.0.7         |    h14c3975_1002          26 KB  conda-forge\n",
            "    xorg-libice-1.0.10         |       h516909a_0          57 KB  conda-forge\n",
            "    xorg-libsm-1.2.3           |    h84519dc_1000          25 KB  conda-forge\n",
            "    xorg-libx11-1.6.9          |       h516909a_0         918 KB  conda-forge\n",
            "    xorg-libxau-1.0.9          |       h14c3975_0          13 KB  conda-forge\n",
            "    xorg-libxdmcp-1.1.3        |       h516909a_0          18 KB  conda-forge\n",
            "    xorg-libxext-1.3.4         |       h516909a_0          51 KB  conda-forge\n",
            "    xorg-libxrender-0.9.10     |    h516909a_1002          31 KB  conda-forge\n",
            "    xorg-renderproto-0.11.1    |    h14c3975_1002           8 KB  conda-forge\n",
            "    xorg-xextproto-7.3.0       |    h14c3975_1002          27 KB  conda-forge\n",
            "    xorg-xproto-7.0.31         |    h14c3975_1007          72 KB  conda-forge\n",
            "    zstd-1.4.3                 |       h3b9ef0a_0         935 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       105.8 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  boost              conda-forge/linux-64::boost-1.70.0-py37h9de70de_1\n",
            "  boost-cpp          conda-forge/linux-64::boost-cpp-1.70.0-h8e57a91_2\n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h516909a_1\n",
            "  cairo              conda-forge/linux-64::cairo-1.16.0-hfb77d84_1002\n",
            "  fontconfig         conda-forge/linux-64::fontconfig-2.13.1-h86ecdb6_1001\n",
            "  freetype           conda-forge/linux-64::freetype-2.10.0-he983fc9_1\n",
            "  gettext            conda-forge/linux-64::gettext-0.19.8.1-hc5be6a0_1002\n",
            "  glib               conda-forge/linux-64::glib-2.58.3-h6f030ca_1002\n",
            "  icu                conda-forge/linux-64::icu-64.2-he1b5a44_1\n",
            "  jpeg               conda-forge/linux-64::jpeg-9c-h14c3975_1001\n",
            "  libblas            conda-forge/linux-64::libblas-3.8.0-14_openblas\n",
            "  libcblas           conda-forge/linux-64::libcblas-3.8.0-14_openblas\n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-7.3.0-hdf63c60_2\n",
            "  libiconv           conda-forge/linux-64::libiconv-1.15-h516909a_1005\n",
            "  liblapack          conda-forge/linux-64::liblapack-3.8.0-14_openblas\n",
            "  libopenblas        conda-forge/linux-64::libopenblas-0.3.7-h6e990d7_3\n",
            "  libpng             conda-forge/linux-64::libpng-1.6.37-hed695b0_0\n",
            "  libtiff            conda-forge/linux-64::libtiff-4.1.0-hfc65ed5_0\n",
            "  libuuid            conda-forge/linux-64::libuuid-2.32.1-h14c3975_1000\n",
            "  libxcb             conda-forge/linux-64::libxcb-1.13-h14c3975_1002\n",
            "  libxml2            conda-forge/linux-64::libxml2-2.9.10-hee79883_0\n",
            "  lz4-c              conda-forge/linux-64::lz4-c-1.8.3-he1b5a44_1001\n",
            "  numpy              conda-forge/linux-64::numpy-1.17.3-py37h95a1406_0\n",
            "  olefile            conda-forge/noarch::olefile-0.46-py_0\n",
            "  pandas             conda-forge/linux-64::pandas-0.25.3-py37hb3f55d8_0\n",
            "  pcre               conda-forge/linux-64::pcre-8.43-he1b5a44_0\n",
            "  pillow             pkgs/main/linux-64::pillow-6.2.0-py37h34e0f95_0\n",
            "  pixman             conda-forge/linux-64::pixman-0.38.0-h516909a_1003\n",
            "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-h14c3975_1001\n",
            "  pycairo            conda-forge/linux-64::pycairo-1.18.2-py37h438ddbb_0\n",
            "  python-dateutil    conda-forge/noarch::python-dateutil-2.8.1-py_0\n",
            "  pytz               conda-forge/noarch::pytz-2019.3-py_0\n",
            "  rdkit              conda-forge/linux-64::rdkit-2019.03.4-py37hb31dc5d_1\n",
            "  xorg-kbproto       conda-forge/linux-64::xorg-kbproto-1.0.7-h14c3975_1002\n",
            "  xorg-libice        conda-forge/linux-64::xorg-libice-1.0.10-h516909a_0\n",
            "  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.3-h84519dc_1000\n",
            "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.6.9-h516909a_0\n",
            "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.9-h14c3975_0\n",
            "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.3-h516909a_0\n",
            "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.4-h516909a_0\n",
            "  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.10-h516909a_1002\n",
            "  xorg-renderproto   conda-forge/linux-64::xorg-renderproto-0.11.1-h14c3975_1002\n",
            "  xorg-xextproto     conda-forge/linux-64::xorg-xextproto-7.3.0-h14c3975_1002\n",
            "  xorg-xproto        conda-forge/linux-64::xorg-xproto-7.0.31-h14c3975_1007\n",
            "  zstd               conda-forge/linux-64::zstd-1.4.3-h3b9ef0a_0\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  ca-certificates    pkgs/main::ca-certificates-2019.10.16~ --> conda-forge::ca-certificates-2019.9.11-hecc5488_0\n",
            "  certifi                                         pkgs/main --> conda-forge\n",
            "  conda                                           pkgs/main --> conda-forge\n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "\n",
            "real\t0m45.419s\n",
            "user\t0m35.463s\n",
            "sys\t0m4.489s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URD3QbUT6J83",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "c6d6858d-33bc-493b-b44a-e58f36c50a99"
      },
      "source": [
        "#Read smiles files\n",
        "maxlen = 64\n",
        "with open('/content/gdrive/My Drive/Colab Notebooks/smiles.txt') as f:\n",
        "  smiles = f.readlines()[:]\n",
        "  smiles = [s.strip() for s in smiles]\n",
        "  smiles = [s.split()[1] for s in smiles]\n",
        "  smiles = [s for s in smiles if len(s)<maxlen]\n",
        "\n",
        "#Characters of smiles\n",
        "all_smiles=''\n",
        "for s in smiles: all_smiles+=s\n",
        "chars = sorted(list(set(list(all_smiles))))\n",
        "#chars.append('X')\n",
        "c_to_i = {c:i for i,c in enumerate(chars)}\n",
        "print ('Max len:', maxlen)\n",
        "print ('Number of chars:', len(chars))\n",
        "print (chars)\n",
        "print (c_to_i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max len: 64\n",
            "Number of chars: 45\n",
            "['#', '(', ')', '+', '-', '.', '/', '1', '2', '3', '4', '5', '6', '7', '=', '@', 'B', 'C', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'S', 'V', 'Z', '[', '\\\\', ']', 'a', 'c', 'e', 'g', 'i', 'l', 'n', 'o', 'r', 's', 'u']\n",
            "{'#': 0, '(': 1, ')': 2, '+': 3, '-': 4, '.': 5, '/': 6, '1': 7, '2': 8, '3': 9, '4': 10, '5': 11, '6': 12, '7': 13, '=': 14, '@': 15, 'B': 16, 'C': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'K': 22, 'L': 23, 'M': 24, 'N': 25, 'O': 26, 'P': 27, 'S': 28, 'V': 29, 'Z': 30, '[': 31, '\\\\': 32, ']': 33, 'a': 34, 'c': 35, 'e': 36, 'g': 37, 'i': 38, 'l': 39, 'n': 40, 'o': 41, 'r': 42, 's': 43, 'u': 44}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuimkDqR_OSk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ea713892-7072-427f-a4d3-c791dda2c34b"
      },
      "source": [
        "#Calculate  LogP of each molecule\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem.Crippen import MolLogP\n",
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "\n",
        "Y = []\n",
        "num_data = 20000\n",
        "st = time.time()\n",
        "for s in smiles[:num_data]:\n",
        "  m = Chem.MolFromSmiles(s)\n",
        "  logp = MolLogP(m)\n",
        "  Y.append(logp)\n",
        "  #Y.append(1)\n",
        "end = time.time()\n",
        "\n",
        "print (f'Time:{(end-st):.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time:14.066\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrmfe5JI5bX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dataset\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class MolDataset(Dataset):\n",
        "    def __init__(self, smiles, properties, c_to_i, maxlen):\n",
        "      self.c_to_i = c_to_i\n",
        "      self.maxlen = maxlen\n",
        "      self.smiles = smiles\n",
        "      self.properties = properties\n",
        "      \n",
        "    def __len__(self):\n",
        "        return len(self.smiles)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        s = self.smiles[idx]\n",
        "        i = torch.from_numpy(np.array([c_to_i[c] for c in s]))\n",
        "        sample = dict()\n",
        "        sample['X'] = i\n",
        "        sample['L'] = len(s)\n",
        "        sample['Y'] = self.properties[idx]\n",
        "        return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxLWr8S0IhH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Collate fn\n",
        "def my_collate(batch):\n",
        "    sample = dict()\n",
        "    X =  torch.nn.utils.rnn.pad_sequence([b['X'] for b in batch], batch_first=True, padding_value = 45)\n",
        "    Y = torch.Tensor([b['Y'] for b in batch])\n",
        "    L = torch.Tensor([b['L'] for b in batch])\n",
        "\n",
        "    sample['X'] = X\n",
        "    sample['Y'] = Y\n",
        "    sample['L'] = L\n",
        "\n",
        "    return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe0jyiNyBhdk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GRURegressor(torch.nn.Module):\n",
        "  def __init__(self, n_feature=128, n_rnn_layer = 1, n_char=46, dropout = 0, using = 0):\n",
        "    #using : 0 = last output, 1 = all output, 2 = last hidden\n",
        "    super(GRURegressor, self).__init__()\n",
        "    self.rnn = nn.GRU(input_size=n_feature, hidden_size=n_feature, num_layers=n_rnn_layer, dropout = dropout)\n",
        "    if(using == 0):\n",
        "      self.fc = nn.Linear(n_feature, 1)\n",
        "    elif(using == 1):\n",
        "      self.fc = nn.Linear(n_feature * maxlen, 1)\n",
        "    else:\n",
        "      self.fc = nn.Linear(n_feature * n_rnn_layer, 1)\n",
        "    self.embedding = nn.Embedding(n_char, n_feature)\n",
        "    self.using = using\n",
        "    self.n_feature = n_feature\n",
        "\n",
        "  def forward(self, x, l):\n",
        "    x = self.embedding(x)\n",
        "    x = x.permute((1,0,2)) # batch, sequence, channel\n",
        "    output, h_n = self.rnn(x)\n",
        "    selected = []\n",
        "\n",
        "    if(self.using == 0):\n",
        "      for i in range(len(l)):\n",
        "        selected.append(output[l[i]-1, i])\n",
        "\n",
        "    elif(self.using == 1):\n",
        "      for i in range(len(l)):\n",
        "        selected.append(torch.cat([output[:l[i], i, :], torch.zeros(maxlen - l[i], self.n_feature).cuda()], 0))\n",
        "\n",
        "    else:\n",
        "      for i in range(len(l)):\n",
        "        selected.append(h_n[:, i, :])\n",
        "\n",
        "    selected = torch.stack(selected)\n",
        "    selected = selected.reshape(selected.size(0), -1)\n",
        "    retval = self.fc(selected)\n",
        "    return retval\n",
        "\n",
        "class RNNRegressor(torch.nn.Module):\n",
        "  def __init__(self, n_feature=128, n_rnn_layer = 1, n_char=46, dropout = 0, using = 0):\n",
        "    super(RNNRegressor, self).__init__()\n",
        "    self.rnn = nn.RNN(input_size=n_feature, hidden_size=n_feature, num_layers=n_rnn_layer, dropout = dropout)\n",
        "    if(using == 0):\n",
        "      self.fc = nn.Linear(n_feature, 1)\n",
        "    elif(using == 1):\n",
        "      self.fc = nn.Linear(n_feature * maxlen, 1)\n",
        "    else:\n",
        "      self.fc = nn.Linear(n_feature * n_rnn_layer, 1)\n",
        "    self.embedding = nn.Embedding(n_char, n_feature)\n",
        "    self.using = using\n",
        "    self.n_feature = n_feature\n",
        "\n",
        "  def forward(self, x, l):\n",
        "    x = self.embedding(x)\n",
        "    x = x.permute((1,0,2)) # batch, sequence, channel\n",
        "    output, h_n = self.rnn(x)\n",
        "    selected = []\n",
        "\n",
        "    if(self.using == 0):\n",
        "      for i in range(len(l)):\n",
        "        selected.append(output[l[i]-1, i])\n",
        "\n",
        "    elif(self.using == 1):\n",
        "      for i in range(len(l)):\n",
        "        selected.append(torch.cat([output[:l[i], i, :], torch.zeros(maxlen - l[i], self.n_feature).cuda()], 0))\n",
        "\n",
        "    else:\n",
        "      for i in range(len(l)):\n",
        "        selected.append(h_n[:, i, :])\n",
        "    \n",
        "    selected = torch.stack(selected)\n",
        "    selected = selected.reshape(selected.size(0), -1)\n",
        "    retval = self.fc(selected)\n",
        "    return retval\n",
        "\n",
        "class LSTMRegressor(torch.nn.Module):\n",
        "  def __init__(self, n_feature=128, n_rnn_layer = 1, n_char=46, dropout = 0, using = 0):\n",
        "    super(LSTMRegressor, self).__init__()\n",
        "    self.rnn = nn.LSTM(input_size=n_feature, hidden_size=n_feature, num_layers=n_rnn_layer, dropout = dropout)\n",
        "    if(using == 0):\n",
        "      self.fc = nn.Linear(n_feature, 1)\n",
        "    elif(using == 1):\n",
        "      self.fc = nn.Linear(n_feature * maxlen, 1)\n",
        "    else:\n",
        "      self.fc = nn.Linear(n_feature * n_rnn_layer, 1)\n",
        "    self.embedding = nn.Embedding(n_char, n_feature)\n",
        "    self.using = using\n",
        "    self.n_feature = n_feature\n",
        "\n",
        "  def forward(self, x, l):\n",
        "    x = self.embedding(x)\n",
        "    x = x.permute((1,0,2)) # batch, sequence, channel\n",
        "    output, h_n = self.rnn(x)\n",
        "    selected = []\n",
        "\n",
        "    if(self.using == 0):\n",
        "      for i in range(len(l)):\n",
        "        selected.append(output[l[i]-1, i])\n",
        "\n",
        "    elif(self.using == 1):\n",
        "      for i in range(len(l)):\n",
        "        selected.append(torch.cat([output[:l[i], i, :], torch.zeros(maxlen - l[i], self.n_feature).cuda()], 0))\n",
        "\n",
        "    else:\n",
        "      for i in range(len(l)):\n",
        "        selected.append(h_n[0][:, i, :])\n",
        "    \n",
        "    selected = torch.stack(selected)\n",
        "    selected = selected.reshape(selected.size(0), -1)\n",
        "    retval = self.fc(selected)\n",
        "    return retval\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYTLZlwu8thG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "a842108a-e7d5-46d7-8105-0f0ab501e0dd"
      },
      "source": [
        "#Train model\n",
        "import time\n",
        "lr = 1e-4\n",
        "GRU_64_1_0 = GRURegressor(64, 1, 46, using = 0).cuda()\n",
        "GRU_64_1_1 = GRURegressor(64, 1, 46, using = 1).cuda()\n",
        "GRU_64_1_2 = GRURegressor(64, 1, 46, using = 2).cuda()\n",
        "\n",
        "RNN_64_1_0 = RNNRegressor(64, 1, 46, using = 0).cuda()\n",
        "RNN_64_1_1 = RNNRegressor(64, 1, 46, using = 1).cuda()\n",
        "RNN_64_1_2 = RNNRegressor(64, 1, 46, using = 2).cuda()\n",
        "\n",
        "LSTM_64_1_0 = LSTMRegressor(64, 1, 46, using = 0).cuda()\n",
        "LSTM_64_1_1 = LSTMRegressor(64, 1, 46, using = 1).cuda()\n",
        "LSTM_64_1_2 = LSTMRegressor(64, 1, 46, using = 2).cuda()\n",
        "\n",
        "GRU_128_1_0 = GRURegressor(128, 1, 46, using = 0).cuda()\n",
        "GRU_128_1_1 = GRURegressor(128, 1, 46, using = 1).cuda()\n",
        "GRU_128_1_2 = GRURegressor(128, 1, 46, using = 2).cuda()\n",
        "\n",
        "RNN_128_1_0 = RNNRegressor(128, 1, 46, using = 0).cuda()\n",
        "RNN_128_1_1 = RNNRegressor(128, 1, 46, using = 1).cuda()\n",
        "RNN_128_1_2 = RNNRegressor(128, 1, 46, using = 2).cuda()\n",
        "\n",
        "LSTM_128_1_0 = LSTMRegressor(128, 1, 46, using = 0).cuda()\n",
        "LSTM_128_1_1 = LSTMRegressor(128, 1, 46, using = 1).cuda()\n",
        "LSTM_128_1_2 = LSTMRegressor(128, 1, 46, using = 2).cuda()\n",
        "\n",
        "GRU_64_3_0 = GRURegressor(64, 3, 46, using = 0).cuda()\n",
        "GRU_64_3_1 = GRURegressor(64, 3, 46, using = 1).cuda()\n",
        "GRU_64_3_2 = GRURegressor(64, 3, 46, using = 2).cuda()\n",
        "\n",
        "RNN_64_3_0 = RNNRegressor(64, 3, 46, using = 0).cuda()\n",
        "RNN_64_3_1 = RNNRegressor(64, 3, 46, using = 1).cuda()\n",
        "RNN_64_3_2 = RNNRegressor(64, 3, 46, using = 2).cuda()\n",
        "\n",
        "LSTM_64_3_0 = LSTMRegressor(64, 3, 46, using = 0).cuda()\n",
        "LSTM_64_3_1 = LSTMRegressor(64, 3, 46, using = 1).cuda()\n",
        "LSTM_64_3_2 = LSTMRegressor(64, 3, 46, using = 2).cuda()\n",
        "\n",
        "GRU_128_3_0 = GRURegressor(128, 3, 46, using = 0).cuda()\n",
        "GRU_128_3_1 = GRURegressor(128, 3, 46, using = 1).cuda()\n",
        "GRU_128_3_2 = GRURegressor(128, 3, 46, using = 2).cuda()\n",
        "\n",
        "RNN_128_3_0 = RNNRegressor(128, 3, 46, using = 0).cuda()\n",
        "RNN_128_3_1 = RNNRegressor(128, 3, 46, using = 1).cuda()\n",
        "RNN_128_3_2 = RNNRegressor(128, 3, 46, using = 2).cuda()\n",
        "\n",
        "LSTM_128_3_0 = LSTMRegressor(128, 3, 46, using = 0).cuda()\n",
        "LSTM_128_3_1 = LSTMRegressor(128, 3, 46, using = 1).cuda()\n",
        "LSTM_128_3_2 = LSTMRegressor(128, 3, 46, using = 2).cuda()\n",
        "\n",
        "GRU_64_3_1_dropout = GRURegressor(64, 3, 46, using = 1, dropout = 0.3).cuda()\n",
        "GRU_128_3_1_dropout = GRURegressor(128, 3, 46, using = 1, dropout = 0.3).cuda()\n",
        "\n",
        "# model_list  = [GRU_64_1_0, GRU_64_1_1, GRU_64_1_2, \n",
        "#                GRU_64_3_0, GRU_64_3_1, GRU_64_3_2,\n",
        "#                RNN_64_1_0, RNN_64_1_1, RNN_64_1_2, \n",
        "#                RNN_64_3_0, RNN_64_3_1, RNN_64_3_2, \n",
        "#                LSTM_64_1_0, LSTM_64_1_1, LSTM_64_1_2,\n",
        "#                LSTM_64_3_0, LSTM_64_3_1, LSTM_64_3_2,\n",
        "\n",
        "#                GRU_128_1_0, GRU_128_1_1, GRU_128_1_2, \n",
        "#                GRU_128_3_0, GRU_128_3_1, GRU_128_3_2,\n",
        "#                RNN_128_1_0, RNN_128_1_1, RNN_128_1_2, \n",
        "#                RNN_128_3_0, RNN_128_3_1, RNN_128_3_2, \n",
        "#                LSTM_128_1_0, LSTM_128_1_1, LSTM_128_1_2, \n",
        "#                LSTM_128_3_0, LSTM_128_3_1, LSTM_128_3_2]\n",
        "\n",
        "model_list  = [GRU_64_1_1, GRU_128_1_1,\n",
        "               GRU_64_3_1, GRU_128_3_1, \n",
        "               GRU_64_3_1_dropout, GRU_128_3_1_dropout]\n",
        "result = []\n",
        "\n",
        "#Dataset\n",
        "train_smiles = smiles[:19000]\n",
        "test_smiles = smiles[19000:20000]\n",
        "train_logp = Y[:19000]\n",
        "test_logp = Y[19000:20000]\n",
        "train_dataset = MolDataset(train_smiles, train_logp, c_to_i, maxlen)\n",
        "test_dataset = MolDataset(test_smiles, test_logp, c_to_i, maxlen)\n",
        "\n",
        "#Dataloader\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=128, num_workers=1, collate_fn=my_collate)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=128, num_workers=1, collate_fn=my_collate)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "def train(model):\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "  #optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "  loss_list = []\n",
        "  st = time.time()\n",
        "\n",
        "  for epoch in range(10):\n",
        "    epoch_loss = []\n",
        "    for i_batch, batch in enumerate(train_dataloader):\n",
        "      x, y, l = \\\n",
        "        batch['X'].cuda().long(), batch['Y'].cuda().float(), batch['L'].cuda().long()\n",
        "      pred = model(x, l).squeeze(-1)\n",
        "      loss = loss_fn(pred, y)\n",
        "      loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "      optimizer.step()\n",
        "      loss_list.append(loss.data.cpu().numpy())\n",
        "      epoch_loss.append(loss.data.cpu().numpy())\n",
        "    if True: print (epoch, np.mean(np.array(epoch_loss)))\n",
        "  end = time.time()\n",
        "  print ('Time:', end-st, '\\n\\n')\n",
        "  return model, loss_list\n",
        "\n",
        "\n",
        "for i in model_list:\n",
        "  result.append(train(i))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 1.9177263\n",
            "1 0.79179025\n",
            "2 0.554717\n",
            "3 0.37328088\n",
            "4 0.26690754\n",
            "5 0.22686401\n",
            "6 0.1925548\n",
            "7 0.17558318\n",
            "8 0.15551768\n",
            "9 0.14200218\n",
            "Time: 139.52117586135864 \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlmkEseBG3c4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Save model\n",
        "fn = '/content/gdrive/My Drive/save'+'.pt'\n",
        "torch.save(model.state_dict(), fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVoKiTbHHdUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load model\n",
        "model.load_state_dict(torch.load(fn))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8YCGk-PG3Ao",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "eb16ed75-c4f4-44ef-e859-9df9c0f2b923"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i in range(len(result)):\n",
        "  plt.plot(result[i][1])\n",
        "  plt.xlabel('Num iteration')\n",
        "  plt.ylabel('Loss')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS0T7Prf9sYJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "c6baebed-5c73-42a6-fb7b-3c6f54805071"
      },
      "source": [
        "#Test model\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "def loss_check(model):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    y_pred_train, y_pred_test = [], []\n",
        "    loss_train, loss_test = [], []\n",
        "    pred_train, pred_test = [], []\n",
        "    true_train, true_test = [], []\n",
        "\n",
        "    \n",
        "    for batch in train_dataloader:\n",
        "      x, y, l = \\\n",
        "        batch['X'].cuda().long(), batch['Y'].cuda().float(), batch['L'].cuda().long()\n",
        "      pred = model(x, l).squeeze(-1)\n",
        "      pred_train.append(pred.data.cpu().numpy())\n",
        "      true_train.append(y.data.cpu().numpy())\n",
        "\n",
        "      loss_train.append(loss_fn(y, pred).data.cpu().numpy())\n",
        "    \n",
        "    for batch in test_dataloader:\n",
        "      x, y, l = \\\n",
        "        batch['X'].cuda().long(), batch['Y'].cuda().float(), batch['L'].cuda().long()\n",
        "      pred = model(x, l).squeeze(-1)\n",
        "      pred_test.append(pred.data.cpu().numpy())\n",
        "      true_test.append(y.data.cpu().numpy())\n",
        "      loss_test.append(loss_fn(y, pred).data.cpu().numpy())\n",
        "\n",
        "  pred_train = np.concatenate(pred_train, -1)\n",
        "  pred_test = np.concatenate(pred_test, -1)\n",
        "  true_train = np.concatenate(true_train, -1)\n",
        "  true_test = np.concatenate(true_test, -1)\n",
        "      \n",
        "  print ('Train loss:', np.mean(np.array(loss_train)))\n",
        "  print ('Test loss:', np.mean(np.array(loss_test)), '\\n\\n')\n",
        "\n",
        "for i in range(len(result)):\n",
        "  loss_check(result[i][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.15395482\n",
            "Test loss: 0.14175563 \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6J1NhViDX0l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a0f5f4ec-a7c1-43e5-8d49-73c8e4582fbc"
      },
      "source": [
        "\n",
        "# plt.scatter(true_train, pred_train, s=1)\n",
        "# plt.scatter(true_test, pred_test, s=1)\n",
        "\n",
        "# plt.plot([-8,12], [-8,12])\n",
        "# plt.xlabel('True')\n",
        "# plt.ylabel('Pred')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "asb \n",
            "\n",
            "abasdf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzLrxKGPD-TS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}