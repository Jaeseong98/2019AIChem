{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Project_MPNN",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jaeseong98/2019AIChem/blob/master/Final_Project_MPNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEhovdMpvPSM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "352f5d1f-8f35-468f-9691-c9c35e3ef563"
      },
      "source": [
        "#Set google drive\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkG_KLMDw4Y6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "079b8ae7-c9a4-4ac8-fb48-c1febe251872"
      },
      "source": [
        "#Install miniconda and rdkit\n",
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!time bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!time conda install -q -y -c conda-forge rdkit\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-15 16:49:18--  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.201.79, 104.18.200.79, 2606:4700::6812:c94f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.201.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - asn1crypto==1.2.0=py37_0\n",
            "    - ca-certificates==2019.10.16=0\n",
            "    - certifi==2019.9.11=py37_0\n",
            "    - cffi==1.13.0=py37h2e261b9_0\n",
            "    - chardet==3.0.4=py37_1003\n",
            "    - conda-package-handling==1.6.0=py37h7b6447c_0\n",
            "    - conda==4.7.12=py37_0\n",
            "    - cryptography==2.8=py37h1ba5d50_0\n",
            "    - idna==2.8=py37_0\n",
            "    - libedit==3.1.20181209=hc058e9b_0\n",
            "    - libffi==3.2.1=hd88cf55_4\n",
            "    - libgcc-ng==9.1.0=hdf63c60_0\n",
            "    - libstdcxx-ng==9.1.0=hdf63c60_0\n",
            "    - ncurses==6.1=he6710b0_1\n",
            "    - openssl==1.1.1d=h7b6447c_3\n",
            "    - pip==19.3.1=py37_0\n",
            "    - pycosat==0.6.3=py37h14c3975_0\n",
            "    - pycparser==2.19=py37_0\n",
            "    - pyopenssl==19.0.0=py37_0\n",
            "    - pysocks==1.7.1=py37_0\n",
            "    - python==3.7.4=h265db76_1\n",
            "    - readline==7.0=h7b6447c_5\n",
            "    - requests==2.22.0=py37_0\n",
            "    - ruamel_yaml==0.15.46=py37h14c3975_0\n",
            "    - setuptools==41.4.0=py37_0\n",
            "    - six==1.12.0=py37_0\n",
            "    - sqlite==3.30.0=h7b6447c_0\n",
            "    - tk==8.6.8=hbc83047_0\n",
            "    - tqdm==4.36.1=py_0\n",
            "    - urllib3==1.24.2=py37_0\n",
            "    - wheel==0.33.6=py37_0\n",
            "    - xz==5.2.4=h14c3975_4\n",
            "    - yaml==0.1.7=had09818_2\n",
            "    - zlib==1.2.11=h7b6447c_3\n",
            "\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  openssl            conda-forge::openssl-1.1.1d-h516909a_0 --> pkgs/main::openssl-1.1.1d-h7b6447c_3\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  ca-certificates    conda-forge::ca-certificates-2019.11.~ --> pkgs/main::ca-certificates-2019.10.16-0\n",
            "  certifi            conda-forge::certifi-2019.11.28-py37_0 --> pkgs/main::certifi-2019.9.11-py37_0\n",
            "  conda                     conda-forge::conda-4.8.0-py37_0 --> pkgs/main::conda-4.7.12-py37_0\n",
            "\n",
            "\n",
            "Preparing transaction: | \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "\n",
            "real\t0m23.472s\n",
            "user\t0m32.163s\n",
            "sys\t0m4.633s\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - rdkit\n",
            "\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates    pkgs/main::ca-certificates-2019.10.16~ --> conda-forge::ca-certificates-2019.11.28-hecc5488_0\n",
            "  certifi               pkgs/main::certifi-2019.9.11-py37_0 --> conda-forge::certifi-2019.11.28-py37_0\n",
            "  conda                      pkgs/main::conda-4.7.12-py37_0 --> conda-forge::conda-4.8.0-py37_0\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  openssl              pkgs/main::openssl-1.1.1d-h7b6447c_3 --> conda-forge::openssl-1.1.1d-h516909a_0\n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "\n",
            "real\t0m6.486s\n",
            "user\t0m5.711s\n",
            "sys\t0m0.875s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkEa1uSP-8JT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl\n",
        "# !pip3 install torchvision\n",
        "# ! pip install --verbose --no-cache-dir torch-scatter\n",
        "# ! pip install --verbose --no-cache-dir torch-sparse\n",
        "# ! pip install --verbose --no-cache-dir torch-cluster\n",
        "# ! pip install --verbose --no-cache-dir torch-spline-conv\n",
        "# ! pip install torch-geometric\n",
        "\n",
        "#!pip install tensorboard_logger\n",
        "import numpy as np\n",
        "from numpy import linalg\n",
        "import networkx as nx\n",
        "import torch\n",
        "import time\n",
        "import random\n",
        "import copy\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torch.optim.lr_scheduler as lrs\n",
        "import math\n",
        "\n",
        "import rdkit\n",
        "from rdkit.Chem import AllChem \n",
        "from rdkit import Chem\n",
        "from rdkit import rdBase\n",
        "from rdkit.Chem.rdchem import HybridizationType\n",
        "from rdkit import RDConfig\n",
        "from rdkit.Chem import ChemicalFeatures\n",
        "from rdkit.Chem.rdchem import BondType\n",
        "from rdkit.Chem.rdMolTransforms import GetBondLength\n",
        "\n",
        "import os\n",
        "from os import listdir\n",
        "import os.path as osp\n",
        "from os.path import isfile, join\n",
        "\n",
        "from six.moves import urllib\n",
        "import errno\n",
        "import tarfile\n",
        "import tarfile\n",
        "import multiprocessing\n",
        "from joblib import Parallel, delayed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKUkVm4QOb9A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8fb8807f-9a98-452a-bfbc-246c362b08c7"
      },
      "source": [
        "#Process data set\n",
        "def coalesce(index, value):\n",
        "    n = index.max().item() + 1\n",
        "    row, col = index\n",
        "    unique, inv = torch.unique(row * n + col, sorted=True, return_inverse=True)\n",
        "\n",
        "    perm = torch.arange(inv.size(0), dtype=inv.dtype, device=inv.device)\n",
        "    perm = inv.new_empty(unique.size(0)).scatter_(0, inv, perm)\n",
        "    index = torch.stack([row[perm], col[perm]], dim=0)\n",
        "    value = value[perm]\n",
        "\n",
        "    return index, value\n",
        "\n",
        "def data_process():\n",
        "    \n",
        "  path = '/content/gdrive/My Drive/QM9'\n",
        "  suppl = Chem.SDMolSupplier('{}/gdb9.sdf'.format(path))\n",
        "\n",
        "  with open('{}/gdb9.sdf.csv'.format(path), 'r') as f:\n",
        "      target = f.read().split('\\n')[1:-1]\n",
        "      n_target = []\n",
        "      for line in target:\n",
        "        x = line.split(',')\n",
        "        n_target.append([float(x[11]), float(x[14])])\n",
        "      target = n_target\n",
        "\n",
        "  fdef_name = os.path.join(RDConfig.RDDataDir, 'BaseFeatures.fdef')\n",
        "  factory = ChemicalFeatures.BuildFeatureFactory(fdef_name)\n",
        "  data_list = []\n",
        "\n",
        "  for i, mol in enumerate(suppl):\n",
        "    if mol is None:\n",
        "        continue\n",
        "\n",
        "    text = suppl.GetItemText(i)\n",
        "    \n",
        "    num_hs = []\n",
        "    for atom in mol.GetAtoms():\n",
        "        num_hs.append(atom.GetTotalNumHs())\n",
        "\n",
        "    mol = Chem.AddHs(mol)\n",
        "    feats = factory.GetFeaturesForMol(mol)\n",
        "\n",
        "    H_type = []\n",
        "    C_type = []\n",
        "    N_type = []\n",
        "    O_type = []\n",
        "    F_type = []\n",
        "    atomic_number = []\n",
        "    sp = []\n",
        "    sp2 = []\n",
        "    sp3 = []\n",
        "    aromatic = []\n",
        "    acceptor = []\n",
        "    donor = []\n",
        "\n",
        "    # Example 130669 has an error and yields a different number of atoms.\n",
        "    # We discard it.\n",
        "    if i == 130669:\n",
        "        continue\n",
        "\n",
        "    num_atoms = mol.GetNumAtoms()\n",
        "\n",
        "    if i%10000 is 0: print(i)\n",
        "    \n",
        "    pos = text.split('\\n')[4:4 + num_atoms]\n",
        "    pos = [[float(x) for x in line.split()[:3]] for line in pos]\n",
        "\n",
        "    for j in range(num_atoms):\n",
        "        atom = mol.GetAtomWithIdx(j)\n",
        "        symbol = atom.GetSymbol()\n",
        "        H_type.append(1 if symbol == 'H' else 0)\n",
        "        C_type.append(1 if symbol == 'C' else 0)\n",
        "        N_type.append(1 if symbol == 'N' else 0)\n",
        "        O_type.append(1 if symbol == 'O' else 0)\n",
        "        F_type.append(1 if symbol == 'F' else 0)\n",
        "        atomic_number.append(atom.GetAtomicNum())\n",
        "        hybridization = atom.GetHybridization()\n",
        "        sp.append(1 if hybridization == HybridizationType.SP else 0)\n",
        "        sp2.append(1 if hybridization == HybridizationType.SP2 else 0)\n",
        "        sp3.append(1 if hybridization == HybridizationType.SP3 else 0)\n",
        "        aromatic.append(1 if atom.GetIsAromatic() else 0)\n",
        "        acceptor.append(0)\n",
        "        donor.append(0)\n",
        "\n",
        "        if symbol == 'H':\n",
        "            num_hs.insert(j, 0)\n",
        "\n",
        "    for j in range(0, len(feats)):\n",
        "        if feats[j].GetFamily() == 'Donor':\n",
        "            node_list = feats[j].GetAtomIds()\n",
        "            for j in node_list:\n",
        "                donor[j] = 1\n",
        "        elif feats[j].GetFamily() == 'Acceptor':\n",
        "            node_list = feats[j].GetAtomIds()\n",
        "            for j in node_list:\n",
        "                acceptor[j] = 1\n",
        "\n",
        "    x = [\n",
        "        H_type, C_type, N_type, O_type, F_type, atomic_number, acceptor, donor,\n",
        "        aromatic, sp, sp2, sp3, num_hs\n",
        "    ]\n",
        "    x = np.asarray(x).transpose()\n",
        "    pos = torch.tensor(pos, dtype=torch.float).numpy()\n",
        "    y = np.asarray(target[i])\n",
        "\n",
        "    chem, raw, bins = [], [], []\n",
        "    step = (6-2)/8.0\n",
        "    start = 2\n",
        "\n",
        "    for v_i in range(0, num_atoms):\n",
        "          for v_j in range(0, num_atoms):\n",
        "              e_ij = mol.GetBondBetweenAtoms(v_i, v_j)\n",
        "\n",
        "              feat = []\n",
        "\n",
        "              if e_ij is not None :\n",
        "                bond_type = e_ij.GetBondType()\n",
        "                feat = [int(bond_type == x) for x in [rdkit.Chem.rdchem.BondType.SINGLE, rdkit.Chem.rdchem.BondType.DOUBLE,\n",
        "                                                              rdkit.Chem.rdchem.BondType.TRIPLE, rdkit.Chem.rdchem.BondType.AROMATIC]]\n",
        "              \n",
        "              else:\n",
        "                feat = [0, 0, 0, 0]\n",
        "                \n",
        "              dist = np.linalg.norm(pos[v_i]-pos[v_j])\n",
        "              bin_feat = copy.deepcopy(feat)\n",
        "              \n",
        "              b = 9\n",
        "              dist_bin = [0 for bin_iter in range(10)]\n",
        "              for k in range(0, 9):\n",
        "                  if dist < (start+k*step):\n",
        "                      b = k\n",
        "                      break\n",
        "              \n",
        "              dist_bin[b] = 1\n",
        "              bin_feat = bin_feat + dist_bin\n",
        "              bins.append(bin_feat)\n",
        "\n",
        "    size = (num_atoms, num_atoms, -1)\n",
        "\n",
        "    chem = np.asarray(chem).reshape(size)\n",
        "    raw = np.asarray(raw).reshape(size)\n",
        "    bins = np.asarray(bins).reshape(size)\n",
        "\n",
        "    data_list.append({\n",
        "        'x': torch.tensor(x),\n",
        "        'y': torch.tensor(y),\n",
        "        'bins': torch.tensor(bins),\n",
        "    })\n",
        "\n",
        "    \n",
        "  torch.save(data_list, '/content/gdrive/My Drive/QM9/qm9.pt')\n",
        "\n",
        "data_process()\n",
        "\n",
        "qm9 = torch.load('/content/gdrive/My Drive/QM9/qm9.pt')\n",
        "print(qm9[-1])\n",
        "print(len(qm9))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "10000\n",
            "20000\n",
            "30000\n",
            "40000\n",
            "50000\n",
            "60000\n",
            "70000\n",
            "80000\n",
            "90000\n",
            "100000\n",
            "110000\n",
            "120000\n",
            "130000\n",
            "{'x': tensor([[0, 1, 0, 0, 0, 6, 0, 0, 0, 0, 0, 1, 2],\n",
            "        [0, 0, 1, 0, 0, 7, 0, 1, 0, 0, 0, 1, 1],\n",
            "        [0, 1, 0, 0, 0, 6, 0, 0, 0, 0, 0, 1, 1],\n",
            "        [0, 1, 0, 0, 0, 6, 0, 0, 0, 0, 0, 1, 1],\n",
            "        [0, 1, 0, 0, 0, 6, 0, 0, 0, 0, 0, 1, 1],\n",
            "        [0, 0, 0, 1, 0, 8, 1, 0, 0, 0, 0, 1, 0],\n",
            "        [0, 1, 0, 0, 0, 6, 0, 0, 0, 0, 0, 1, 0],\n",
            "        [0, 1, 0, 0, 0, 6, 0, 0, 0, 0, 0, 1, 1],\n",
            "        [0, 1, 0, 0, 0, 6, 0, 0, 0, 0, 0, 1, 1],\n",
            "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]]), 'y': tensor([-400.6331, -400.6622], dtype=torch.float64), 'bins': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [1, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 1]],\n",
            "\n",
            "        [[1, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [1, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 1]],\n",
            "\n",
            "        [[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [1, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 1]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 1]],\n",
            "\n",
            "        [[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 1]],\n",
            "\n",
            "        [[0, 0, 0,  ..., 0, 0, 1],\n",
            "         [0, 0, 0,  ..., 0, 0, 1],\n",
            "         [0, 0, 0,  ..., 0, 0, 1],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 1],\n",
            "         [0, 0, 0,  ..., 0, 0, 1],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]]])}\n",
            "133246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1kAK_h6hSRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Qm9(data.Dataset):\n",
        "\n",
        "    # Constructor\n",
        "    def __init__(self, data_list, ids, target_transform=None, e_representation='raw_distance'):\n",
        "        self.data_list = data_list\n",
        "        self.ids = ids\n",
        "        self.target_transform = target_transform\n",
        "        self.e_representation = e_representation\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        g = self.data_list[self.ids[index]]\n",
        "        h = g['x']\n",
        "        e = g['bins']\n",
        "        target = g['y'][1]\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return (h, e, target)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def set_target_transform(self, target_transform):\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def get_statics(self):\n",
        "\n",
        "        targets = []\n",
        "        for index in range(len(self.ids)):\n",
        "          targets.append(self.data_list[self.ids[index]]['y'][1])\n",
        "        targets = torch.stack(targets)\n",
        "\n",
        "        return torch.mean(targets, dim=0), torch.std(targets, dim=0)\n",
        "\n",
        "def collate_g(batch):\n",
        "\n",
        "    batch_sizes = np.max(np.array([h.size(0) for (h, e, target) in batch]))\n",
        "\n",
        "    h = np.zeros((len(batch), batch_sizes, 13))\n",
        "    e = np.zeros((len(batch), batch_sizes, batch_sizes, 14))\n",
        "    a = np.zeros((len(batch), batch_sizes, batch_sizes))\n",
        "    #target = np.zeros((len(batch), 4))\n",
        "    target = np.zeros((len(batch), 1))\n",
        "\n",
        "    for i in range(len(batch)):\n",
        "\n",
        "        num_nodes = batch[i][0].size(0)\n",
        "        h[i, 0:num_nodes, :] = batch[i][0]\n",
        "        e[i, 0:num_nodes, 0:num_nodes, :] = batch[i][1]\n",
        "\n",
        "        # Target\n",
        "        target[i, :] = batch[i][2]\n",
        "\n",
        "\n",
        "    h = torch.FloatTensor(h)\n",
        "    e = torch.FloatTensor(e)\n",
        "    target = torch.FloatTensor(target)\n",
        "    \n",
        "    return h, e, target\n",
        "\n",
        "def normalize_data(data, mean, std):\n",
        "    data_norm = (data-mean)/std\n",
        "    return data_norm\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPq1p3QR89Dc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NNet(nn.Module):\n",
        "\n",
        "    def __init__(self, n_in, n_out, hlayers=(128, 256, 128)):\n",
        "        super(NNet, self).__init__()\n",
        "        self.n_hlayers = len(hlayers)\n",
        "        self.fcs = nn.ModuleList([nn.Linear(n_in, hlayers[i]) if i == 0 else\n",
        "                                  nn.Linear(hlayers[i-1], n_out) if i == self.n_hlayers else\n",
        "                                  nn.Linear(hlayers[i-1], hlayers[i]) for i in range(self.n_hlayers+1)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i in range(self.n_hlayers):\n",
        "            x = F.relu(self.fcs[i](x))\n",
        "        x = self.fcs[-1](x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3baQH8Fkso6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Set2Set(nn.Module): \n",
        "    def __init__(self, input_dim, M, num_layers=1):\n",
        "        super(Set2Set, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = input_dim*2\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm_output_dim = input_dim\n",
        "        self.lstm = nn.LSTM(input_dim*2, input_dim, num_layers=num_layers, batch_first=True)\n",
        "        self.M = M\n",
        "\n",
        "        self.pred = nn.Linear(input_dim*2, input_dim)\n",
        "        self.act = nn.ReLU()\n",
        "\n",
        "    def forward(self, embedding):\n",
        "        batch_size = embedding.size()[0]\n",
        "        n = embedding.size()[1]\n",
        "\n",
        "        hidden = (torch.zeros(self.num_layers, batch_size, self.lstm_output_dim).cuda(),\n",
        "                  torch.zeros(self.num_layers, batch_size, self.lstm_output_dim).cuda())\n",
        "\n",
        "        q_star = torch.zeros(batch_size, 1, self.hidden_dim).cuda()\n",
        "\n",
        "        for i in range(self.M):\n",
        "            q, hidden = self.lstm(q_star, hidden)\n",
        "            e = embedding @ torch.transpose(q, 1, 2)\n",
        "            a = nn.Softmax(dim=1)(e)\n",
        "            r = torch.sum(a * embedding, dim=1, keepdim=True)\n",
        "            q_star = torch.cat((q, r), dim=2)\n",
        "        q_star = torch.squeeze(q_star, dim=1)\n",
        "        out = self.act(self.pred(q_star))\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ9v_Xy69TmR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def train(train_loader, model, criterion, optimizer, epoch, evaluation, logger=None):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    error_ratio = AverageMeter()\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "\n",
        "    loss_list = []\n",
        "    err_list = []\n",
        "\n",
        "    for i, (h, e, target) in enumerate(train_loader):\n",
        "\n",
        "        # Prepare input data\n",
        "        h, e, target = h.cuda(), e.cuda(), target.cuda()\n",
        "\n",
        "        # Measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Compute output\n",
        "        output = model(h, e)\n",
        "        train_loss = criterion(output, target)\n",
        "        eval_val = evaluation(output, target)\n",
        "\n",
        "        loss_list.append(train_loss.item())\n",
        "        err_list.append(eval_val.item())\n",
        "\n",
        "        # Logs\n",
        "        losses.update(train_loss.item(), h.size(0))\n",
        "        error_ratio.update(eval_val, h.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        train_loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        # Measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % 300 == 0:\n",
        "\n",
        "          print('outputs : ', output[0], target[0])\n",
        "\n",
        "          print('Epoch: [{0}][{1}/{2}]\\t'\n",
        "                'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
        "                'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                'Error Ratio {err.val:.4f} ({err.avg:.4f})'\n",
        "                .format(epoch, i, len(train_loader), batch_time=batch_time,\n",
        "                        data_time=data_time, loss=losses, err=error_ratio))\n",
        "        \n",
        "    if logger is not None:\n",
        "      logger.log_value('train_epoch_loss', losses.avg)\n",
        "      logger.log_value('train_epoch_error_ratio', error_ratio.avg)\n",
        "\n",
        "    print('Epoch: [{0}] Avg Error Ratio {err.avg:.3f}; Average Loss {loss.avg:.3f}; Avg Time x Batch {b_time.avg:.3f}'\n",
        "          .format(epoch, err=error_ratio, loss=losses, b_time=batch_time))\n",
        "    \n",
        "    return loss_list, err_list\n",
        "\n",
        "\n",
        "def validate(val_loader, model, criterion, evaluation, logger=None):\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    error_ratio = AverageMeter()\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (h, e, target) in enumerate(val_loader):\n",
        "\n",
        "        # Prepare input data\n",
        "        h, e, target = h.cuda(), e.cuda(), target.cuda()\n",
        "\n",
        "        # Compute output\n",
        "        output = model(h, e)\n",
        "\n",
        "        # Logs\n",
        "        losses.update(criterion(output, target).item(), h.size(0))\n",
        "        error_ratio.update(evaluation(output, target).item(), h.size(0))\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % 300 == 0:\n",
        "\n",
        "          print('Test: [{0}/{1}]\\t'\n",
        "                'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                'Error Ratio {err.val:.4f} ({err.avg:.4f})'\n",
        "                .format(i, len(val_loader), batch_time=batch_time,\n",
        "                        loss=losses, err=error_ratio))\n",
        "\n",
        "    print(' * Average Error Ratio {err.avg:.3f}; Average Loss {loss.avg:.3f}'\n",
        "          .format(err=error_ratio, loss=losses))\n",
        "\n",
        "    if logger is not None:\n",
        "        logger.log_value('test_epoch_loss', losses.avg)\n",
        "        logger.log_value('test_epoch_error_ratio', error_ratio.avg)\n",
        "\n",
        "    return error_ratio.avg, losses.avg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__Ms-m9D_E7_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "860ea517-3cb7-4f1a-9f65-83970564b46f"
      },
      "source": [
        "print('Prepare files')\n",
        "\n",
        "idx = np.random.permutation(133245)\n",
        "idx = idx.tolist()\n",
        "valid_ids = idx[0:10000]\n",
        "test_ids = idx[10000:20000]\n",
        "train_ids = idx[20000:]\n",
        "\n",
        "# reduce num of dataset for debugging\n",
        "# idx = np.random.permutation(10000)\n",
        "# idx = idx.tolist()\n",
        "# valid_ids = idx[0:1000]\n",
        "# test_ids = idx[1000:2000]\n",
        "# train_ids = idx[2000:]\n",
        "\n",
        "data_train = Qm9(qm9, train_ids)\n",
        "data_valid = Qm9(qm9, valid_ids)\n",
        "data_test = Qm9(qm9, test_ids)\n",
        "\n",
        "train_mean, train_std = data_train.get_statics()\n",
        "\n",
        "data_train.set_target_transform(lambda x: normalize_data(x, train_mean, train_std))\n",
        "data_valid.set_target_transform(lambda x: normalize_data(x, train_mean, train_std))\n",
        "data_test.set_target_transform(lambda x: normalize_data(x, train_mean, train_std))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(data_train,\n",
        "                                            batch_size=128, shuffle=True,\n",
        "                                            collate_fn=collate_g,\n",
        "                                            num_workers=2)\n",
        "valid_loader = torch.utils.data.DataLoader(data_valid,\n",
        "                                            batch_size=128, collate_fn=collate_g,\n",
        "                                            num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(data_test,\n",
        "                                          batch_size=128, collate_fn=collate_g,\n",
        "                                          num_workers=2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prepare files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmNfz3PZj_fF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MessageFunction(nn.Module):\n",
        "  def __init__(self, n_bond, n_atoms):\n",
        "    super(MessageFunction, self).__init__()\n",
        "    self.fcs = NNet(n_in=n_bond, n_out=(n_atoms*n_atoms), hlayers=[128])\n",
        "    #self.fcs = nn.Linear(n_bond, n_atoms*n_atoms)\n",
        "    self.n_bond = n_bond\n",
        "    self.n_atoms = n_atoms\n",
        "    \n",
        "  #from w to v along e : m_wv\n",
        "  def forward(self, h_w, e_vw):\n",
        "    edge_output = self.fcs.forward(e_vw)\n",
        "    edge_output = edge_output.view(edge_output.size(0), edge_output.size(1), self.n_atoms, self.n_atoms)\n",
        "    h_w = torch.unsqueeze(h_w, 3)\n",
        "    h_multiply =  torch.einsum('ijkk,ijkl->ijkl', [edge_output, h_w])\n",
        "    m_new = torch.squeeze(h_multiply)\n",
        "\n",
        "    return m_new\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGag4Ygei70A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class UpdateFunction(nn.Module):\n",
        "  def __init__(self, n_atoms):\n",
        "    super(UpdateFunction, self).__init__()\n",
        "    self.rnn = nn.GRU(input_size=n_atoms, hidden_size=n_atoms)\n",
        "\n",
        "  def forward(self, h_v, m_v):\n",
        "    m_v = torch.unsqueeze(m_v, 1)\n",
        "    h_v = torch.unsqueeze(h_v, 0)\n",
        "    m_v = m_v.permute(1, 0, 2)\n",
        "    h_v = h_v.contiguous()\n",
        "    m_v = m_v.contiguous()\n",
        "    output, h_n = self.rnn.forward(m_v, h_v)  # 0 or 1???\n",
        "    return h_n.permute(1, 0, 2).squeeze()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MYZMp_UK3Re",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReadoutFunction(nn.Module):\n",
        "  def __init__(self, hidden, node, l_target):\n",
        "    super(ReadoutFunction, self).__init__()\n",
        "\n",
        "    self.hidden = hidden\n",
        "    self.node = node\n",
        "    self.l_target = l_target\n",
        "    # self.i = NNet(n_in=2*hidden, n_out=l_target, hlayers=[128])\n",
        "    # self.j = NNet(n_in=hidden, n_out=l_target, hlayers=[128])\n",
        "\n",
        "    # self.i = nn.Linear(2*hidden, l_target)\n",
        "    # self.j = nn.Linear(hidden, l_target)\n",
        "\n",
        "    # 1<=M<=12\n",
        "    self.s2s = Set2Set(hidden+node, 6)\n",
        "    self.out = NNet(hidden+node, l_target, hlayers=[128])\n",
        "\n",
        "  def forward(self, h_t, x):\n",
        "\n",
        "      # Equotion 4 in paper\n",
        "      # i_out = nn.Sigmoid()(self.i(torch.cat([h_0, h_t], 2)))\n",
        "      # j_out = self.j(h_t)\n",
        "      # nn_res = i_out * j_out\n",
        "      # ret = torch.sum(nn_res, 1)\n",
        "\n",
        "      # set2set\n",
        "      tup = torch.cat((h_t, x), dim=2)\n",
        "      q_t = self.s2s.forward(tup)\n",
        "      ret = self.out.forward(q_t)\n",
        "\n",
        "      return ret"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk1Kn_xmK6RV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MPNN(nn.Module):\n",
        "  def __init__(self, n_edge_feats, n_node_feats, n_hidden_feats, n_layers=3, n_towers=1,l_target=1):\n",
        "    super(MPNN, self).__init__()\n",
        "    self.m = nn.ModuleList([MessageFunction(n_edge_feats, n_hidden_feats // n_towers) \n",
        "                              for i in range(n_towers)])\n",
        "\n",
        "    self.u = nn.ModuleList([UpdateFunction(n_hidden_feats // n_towers)\n",
        "                              for i in range(n_towers)])\n",
        "\n",
        "    self.r = ReadoutFunction(n_hidden_feats, n_node_feats, l_target)\n",
        "    self.t = NNet(n_in=n_hidden_feats, n_out=n_hidden_feats, hlayers=[128])\n",
        "    #self.t = nn.Linear(n_hidden_feats, n_hidden_feats)\n",
        "\n",
        "    self.n_layers = n_layers\n",
        "    self.l_target = l_target\n",
        "    self.n_edge_feats = n_edge_feats\n",
        "    self.n_node_feats = n_node_feats\n",
        "    self.n_hidden_feats = n_hidden_feats\n",
        "    self.n_towers = n_towers\n",
        "    self.n_div_feats = n_hidden_feats // n_towers\n",
        "\n",
        "    self.emb = nn.Linear(n_node_feats, n_hidden_feats)\n",
        "    self.test = nn.Linear(n_hidden_feats, l_target)\n",
        "\n",
        "  def forward(self, h_in, e):\n",
        "\n",
        "    h = []\n",
        "    # Padding to some larger dimension d\n",
        "    h_0 = self.emb(h_in)\n",
        "    h.append(h_0)\n",
        "\n",
        "    # Layer\n",
        "    for t in range(0, self.n_layers):\n",
        "\n",
        "        h_t = torch.zeros(h_0.size(0), h_0.size(1), h_0.size(2)).cuda()\n",
        "        # Apply one layer pass (Message + Update)\n",
        "        for v in range(0, h_0.size(1)):\n",
        "            for n in range(self.n_towers):\n",
        "\n",
        "                # Message\n",
        "                m = self.m[n].forward(h[t][:, :, self.n_div_feats*n : self.n_div_feats*(n+1)], e[:, v, :, :])\n",
        "\n",
        "                # Update\n",
        "                h_t[:, v, self.n_div_feats*n : self.n_div_feats*(n+1)] = self.u[n].forward(h[t][:, v, self.n_div_feats*n : self.n_div_feats*(n+1)], torch.sum(m, dim=1))\n",
        "        \n",
        "        if(self.n_towers != 1):\n",
        "          h_t = self.t.forward(h_t)\n",
        "        h.append(h_t)\n",
        "\n",
        "    # Readout\n",
        "    res = self.r.forward(h[-1], h_in)\n",
        "\n",
        "    return res \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou7eLpBbMg_8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "da424429-c0f3-4539-8dc7-46e7f1b7bdd5"
      },
      "source": [
        "model = MPNN(n_edge_feats=14, n_node_feats=13, n_hidden_feats=64, n_layers=3, n_towers=2, l_target=1)\n",
        "\n",
        "#model = torch.load('/content/gdrive/My Drive/QM9/model_best.pt')\n",
        "\n",
        "epochs = 50\n",
        "\n",
        "\n",
        "# lr = random.uniform(1e-5, 5e-4)\n",
        "lr = 1e-5\n",
        "final = random.uniform(0.01, 1.0)\n",
        "print(lr, final)\n",
        "f_lr = lr * final\n",
        "lr_step = (lr - f_lr) / epochs * 0.8\n",
        "print('Optimizer' , str(lr_step))\n",
        "lambda1 = lambda epoch: lr - (epoch - 0.1*epochs)*lr_step\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.MSELoss()\n",
        "evaluation = lambda output, target: torch.mean(torch.abs(output - target) / torch.abs(target))\n",
        "\n",
        "\n",
        "model = model.cuda()\n",
        "criterion = criterion.cuda()\n",
        "\n",
        "best_er1 = 100\n",
        "\n",
        "train_losses = []\n",
        "train_errs = []\n",
        "valid_losses = []\n",
        "valid_errs = []\n",
        "\n",
        "\n",
        "# Epoch for loop\n",
        "for epoch in range(0, epochs):\n",
        "\n",
        "    # train for one epoch\n",
        "    train_loss, train_err = train(train_loader, model, criterion, optimizer, epoch, evaluation)\n",
        "\n",
        "    \n",
        "    train_losses.append(train_loss)\n",
        "    train_errs.append(train_err)\n",
        "\n",
        "    # evaluate on test set\n",
        "    er1, valid_loss = validate(valid_loader, model, criterion, evaluation)\n",
        "\n",
        "    valid_errs.append(math.log(er1))\n",
        "    valid_losses.append(math.log(valid_loss))\n",
        "\n",
        "\n",
        "    if epoch > epochs * 0.1 and epoch < epochs * 0.9:\n",
        "      lr -= lr_step\n",
        "      for param_group in optimizer.param_groups:\n",
        "          param_group['lr'] = lr\n",
        "\n",
        "    if er1 < best_er1:\n",
        "      best_er1 = er1\n",
        "      print(best_er1, epoch)\n",
        "      torch.save(model, '/content/gdrive/My Drive/QM9/mpnn_model_tower.pt')\n",
        "    \n",
        "# For testing\n",
        "test_err, _= validate(test_loader, model, criterion, evaluation)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "concat_train_loss = sum(train_losses, [])\n",
        "concat_train_err = sum(train_errs, [])\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 20))\n",
        "plt.subplot(4, 1, 1)\n",
        "plt.plot(concat_train_loss, 'r')\n",
        "plt.title('MPNN')\n",
        "plt.ylabel('Train Loss')\n",
        "\n",
        "plt.subplot(4, 1, 2)\n",
        "plt.plot(concat_train_err, 'g')\n",
        "plt.title('MPNN')\n",
        "plt.ylabel('Train Error')\n",
        "\n",
        "plt.subplot(4, 1, 3)\n",
        "plt.plot(valid_losses, 'b')\n",
        "plt.title('MPNN')\n",
        "plt.ylabel('Valid Loss')\n",
        "\n",
        "plt.subplot(4, 1, 4)\n",
        "plt.plot(valid_errs, 'm')\n",
        "plt.title('MPNN')\n",
        "plt.ylabel('Valid Error')\n",
        "plt.xlabel('Num iteration')\n",
        "\n",
        "print(test_err)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1e-05 0.7084268991346501\n",
            "Optimizer 4.665169613845599e-08\n",
            "outputs :  tensor([-0.0452], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.2550], device='cuda:0')\n",
            "Epoch: [0][0/885]\tTime 1.406 (1.406)\tData 0.476 (0.476)\tLoss 1.0962 (1.0962)\tError Ratio 1.0009 (1.0009)\n",
            "outputs :  tensor([-0.0417], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.6861], device='cuda:0')\n",
            "Epoch: [0][300/885]\tTime 0.267 (0.302)\tData 0.005 (0.007)\tLoss 1.0275 (1.0052)\tError Ratio 0.9859 (0.9926)\n",
            "outputs :  tensor([0.0656], device='cuda:0', grad_fn=<SelectBackward>) tensor([1.5034], device='cuda:0')\n",
            "Epoch: [0][600/885]\tTime 0.271 (0.293)\tData 0.005 (0.006)\tLoss 0.9751 (0.9779)\tError Ratio 0.9342 (0.9845)\n",
            "Epoch: [0] Avg Error Ratio 0.969; Average Loss 0.931; Avg Time x Batch 0.291\n",
            "Test: [0/79]\tTime 0.598 (0.598)\tLoss 0.4851 (0.4851)\tError Ratio 0.7681 (0.7681)\n",
            " * Average Error Ratio 0.934; Average Loss 0.641\n",
            "0.9342654598236084 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MPNN. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MessageFunction. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type NNet. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type UpdateFunction. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReadoutFunction. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Set2Set. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "outputs :  tensor([-0.0399], device='cuda:0', grad_fn=<SelectBackward>) tensor([1.7102], device='cuda:0')\n",
            "Epoch: [1][0/885]\tTime 0.750 (0.750)\tData 0.402 (0.402)\tLoss 0.6139 (0.6139)\tError Ratio 0.7617 (0.7617)\n",
            "outputs :  tensor([-0.4858], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.6858], device='cuda:0')\n",
            "Epoch: [1][300/885]\tTime 0.317 (0.294)\tData 0.005 (0.006)\tLoss 0.2417 (0.4271)\tError Ratio 0.8121 (0.8127)\n",
            "outputs :  tensor([0.6112], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.2400], device='cuda:0')\n",
            "Epoch: [1][600/885]\tTime 0.302 (0.291)\tData 0.004 (0.005)\tLoss 0.2732 (0.3402)\tError Ratio 0.8084 (0.7772)\n",
            "Epoch: [1] Avg Error Ratio 0.758; Average Loss 0.294; Avg Time x Batch 0.289\n",
            "Test: [0/79]\tTime 0.601 (0.601)\tLoss 0.0378 (0.0378)\tError Ratio 0.2447 (0.2447)\n",
            " * Average Error Ratio 0.742; Average Loss 0.187\n",
            "0.7418639715194703 1\n",
            "outputs :  tensor([-0.2604], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.6560], device='cuda:0')\n",
            "Epoch: [2][0/885]\tTime 0.771 (0.771)\tData 0.412 (0.412)\tLoss 0.2784 (0.2784)\tError Ratio 0.9452 (0.9452)\n",
            "outputs :  tensor([-0.9681], device='cuda:0', grad_fn=<SelectBackward>) tensor([-1.0569], device='cuda:0')\n",
            "Epoch: [2][300/885]\tTime 0.277 (0.290)\tData 0.004 (0.006)\tLoss 0.0343 (0.1557)\tError Ratio 0.4405 (0.6482)\n",
            "outputs :  tensor([1.6070], device='cuda:0', grad_fn=<SelectBackward>) tensor([1.5334], device='cuda:0')\n",
            "Epoch: [2][600/885]\tTime 0.274 (0.288)\tData 0.004 (0.005)\tLoss 0.0279 (0.1456)\tError Ratio 0.2155 (0.6324)\n",
            "Epoch: [2] Avg Error Ratio 0.623; Average Loss 0.138; Avg Time x Batch 0.288\n",
            "Test: [0/79]\tTime 0.553 (0.553)\tLoss 0.0093 (0.0093)\tError Ratio 0.1254 (0.1254)\n",
            " * Average Error Ratio 0.581; Average Loss 0.123\n",
            "0.5806115224838256 2\n",
            "outputs :  tensor([-0.0938], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.1612], device='cuda:0')\n",
            "Epoch: [3][0/885]\tTime 0.752 (0.752)\tData 0.443 (0.443)\tLoss 0.0511 (0.0511)\tError Ratio 0.1712 (0.1712)\n",
            "outputs :  tensor([-1.5168], device='cuda:0', grad_fn=<SelectBackward>) tensor([-1.5813], device='cuda:0')\n",
            "Epoch: [3][300/885]\tTime 0.276 (0.292)\tData 0.004 (0.007)\tLoss 0.0565 (0.0940)\tError Ratio 0.1206 (0.4823)\n",
            "outputs :  tensor([-1.6519], device='cuda:0', grad_fn=<SelectBackward>) tensor([-1.6117], device='cuda:0')\n",
            "Epoch: [3][600/885]\tTime 0.277 (0.290)\tData 0.005 (0.006)\tLoss 0.0085 (0.0863)\tError Ratio 0.2000 (0.4842)\n",
            "Epoch: [3] Avg Error Ratio 0.472; Average Loss 0.080; Avg Time x Batch 0.299\n",
            "Test: [0/79]\tTime 0.766 (0.766)\tLoss 0.0190 (0.0190)\tError Ratio 0.2361 (0.2361)\n",
            " * Average Error Ratio 0.447; Average Loss 0.066\n",
            "0.44748719635009765 3\n",
            "outputs :  tensor([-0.2034], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.1923], device='cuda:0')\n",
            "Epoch: [4][0/885]\tTime 0.825 (0.825)\tData 0.453 (0.453)\tLoss 0.0759 (0.0759)\tError Ratio 0.2625 (0.2625)\n",
            "outputs :  tensor([0.6404], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.5789], device='cuda:0')\n",
            "Epoch: [4][300/885]\tTime 0.275 (0.294)\tData 0.004 (0.007)\tLoss 0.0101 (0.0557)\tError Ratio 0.2478 (0.4050)\n",
            "outputs :  tensor([-0.0960], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.3174], device='cuda:0')\n",
            "Epoch: [4][600/885]\tTime 0.301 (0.291)\tData 0.004 (0.006)\tLoss 0.0336 (0.0527)\tError Ratio 0.3997 (0.3857)\n",
            "Epoch: [4] Avg Error Ratio 0.367; Average Loss 0.049; Avg Time x Batch 0.290\n",
            "Test: [0/79]\tTime 0.584 (0.584)\tLoss 0.0152 (0.0152)\tError Ratio 0.2117 (0.2117)\n",
            " * Average Error Ratio 0.342; Average Loss 0.041\n",
            "0.34152969303131103 4\n",
            "outputs :  tensor([-1.0061], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.9614], device='cuda:0')\n",
            "Epoch: [5][0/885]\tTime 0.739 (0.739)\tData 0.420 (0.420)\tLoss 0.0164 (0.0164)\tError Ratio 0.2227 (0.2227)\n",
            "outputs :  tensor([-0.3925], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.2873], device='cuda:0')\n",
            "Epoch: [5][300/885]\tTime 0.281 (0.294)\tData 0.004 (0.006)\tLoss 0.0322 (0.0338)\tError Ratio 0.3512 (0.2917)\n",
            "outputs :  tensor([0.5619], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.6391], device='cuda:0')\n",
            "Epoch: [5][600/885]\tTime 0.275 (0.292)\tData 0.004 (0.006)\tLoss 0.0050 (0.0309)\tError Ratio 0.1187 (0.2863)\n",
            "Epoch: [5] Avg Error Ratio 0.267; Average Loss 0.027; Avg Time x Batch 0.291\n",
            "Test: [0/79]\tTime 0.599 (0.599)\tLoss 0.0281 (0.0281)\tError Ratio 0.3219 (0.3219)\n",
            " * Average Error Ratio 0.372; Average Loss 0.036\n",
            "outputs :  tensor([-1.7100], device='cuda:0', grad_fn=<SelectBackward>) tensor([-1.5826], device='cuda:0')\n",
            "Epoch: [6][0/885]\tTime 0.756 (0.756)\tData 0.429 (0.429)\tLoss 0.0317 (0.0317)\tError Ratio 0.4719 (0.4719)\n",
            "outputs :  tensor([-0.7290], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.7154], device='cuda:0')\n",
            "Epoch: [6][300/885]\tTime 0.279 (0.293)\tData 0.004 (0.006)\tLoss 0.0446 (0.0189)\tError Ratio 0.1106 (0.2122)\n",
            "outputs :  tensor([-0.7089], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.6869], device='cuda:0')\n",
            "Epoch: [6][600/885]\tTime 0.275 (0.291)\tData 0.008 (0.006)\tLoss 0.0024 (0.0160)\tError Ratio 0.1143 (0.1959)\n",
            "Epoch: [6] Avg Error Ratio 0.182; Average Loss 0.014; Avg Time x Batch 0.302\n",
            "Test: [0/79]\tTime 0.858 (0.858)\tLoss 0.0026 (0.0026)\tError Ratio 0.0776 (0.0776)\n",
            " * Average Error Ratio 0.124; Average Loss 0.011\n",
            "0.12417135467529297 6\n",
            "outputs :  tensor([-0.2120], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.2216], device='cuda:0')\n",
            "Epoch: [7][0/885]\tTime 0.896 (0.896)\tData 0.504 (0.504)\tLoss 0.0148 (0.0148)\tError Ratio 0.0820 (0.0820)\n",
            "outputs :  tensor([-0.4726], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.5625], device='cuda:0')\n",
            "Epoch: [7][300/885]\tTime 0.325 (0.297)\tData 0.004 (0.008)\tLoss 0.0037 (0.0079)\tError Ratio 0.1060 (0.1174)\n",
            "outputs :  tensor([0.1668], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.2408], device='cuda:0')\n",
            "Epoch: [7][600/885]\tTime 0.312 (0.294)\tData 0.005 (0.006)\tLoss 0.0018 (0.0066)\tError Ratio 0.1224 (0.1095)\n",
            "Epoch: [7] Avg Error Ratio 0.104; Average Loss 0.006; Avg Time x Batch 0.294\n",
            "Test: [0/79]\tTime 0.627 (0.627)\tLoss 0.0014 (0.0014)\tError Ratio 0.0592 (0.0592)\n",
            " * Average Error Ratio 0.084; Average Loss 0.006\n",
            "0.08388890438079834 7\n",
            "outputs :  tensor([-0.5130], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.5318], device='cuda:0')\n",
            "Epoch: [8][0/885]\tTime 0.781 (0.781)\tData 0.436 (0.436)\tLoss 0.0018 (0.0018)\tError Ratio 0.0649 (0.0649)\n",
            "outputs :  tensor([-0.4821], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.5313], device='cuda:0')\n",
            "Epoch: [8][300/885]\tTime 0.280 (0.296)\tData 0.004 (0.007)\tLoss 0.0088 (0.0028)\tError Ratio 0.0566 (0.0784)\n",
            "outputs :  tensor([-0.3536], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.3459], device='cuda:0')\n",
            "Epoch: [8][600/885]\tTime 0.361 (0.296)\tData 0.008 (0.006)\tLoss 0.0008 (0.0034)\tError Ratio 0.0448 (0.0745)\n",
            "Epoch: [8] Avg Error Ratio 0.071; Average Loss 0.003; Avg Time x Batch 0.308\n",
            "Test: [0/79]\tTime 0.603 (0.603)\tLoss 0.0007 (0.0007)\tError Ratio 0.0442 (0.0442)\n",
            " * Average Error Ratio 0.064; Average Loss 0.004\n",
            "0.06403456087112427 8\n",
            "outputs :  tensor([1.5318], device='cuda:0', grad_fn=<SelectBackward>) tensor([1.5033], device='cuda:0')\n",
            "Epoch: [9][0/885]\tTime 0.751 (0.751)\tData 0.431 (0.431)\tLoss 0.0008 (0.0008)\tError Ratio 0.0462 (0.0462)\n",
            "outputs :  tensor([0.7692], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.7639], device='cuda:0')\n",
            "Epoch: [9][300/885]\tTime 0.320 (0.295)\tData 0.005 (0.006)\tLoss 0.0006 (0.0023)\tError Ratio 0.0504 (0.0621)\n",
            "outputs :  tensor([-1.2540], device='cuda:0', grad_fn=<SelectBackward>) tensor([-1.2568], device='cuda:0')\n",
            "Epoch: [9][600/885]\tTime 0.274 (0.294)\tData 0.004 (0.006)\tLoss 0.0063 (0.0020)\tError Ratio 0.0614 (0.0597)\n",
            "Epoch: [9] Avg Error Ratio 0.059; Average Loss 0.002; Avg Time x Batch 0.292\n",
            "Test: [0/79]\tTime 0.552 (0.552)\tLoss 0.0005 (0.0005)\tError Ratio 0.0364 (0.0364)\n",
            " * Average Error Ratio 0.054; Average Loss 0.003\n",
            "0.053966568994522096 9\n",
            "outputs :  tensor([-0.6499], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.6545], device='cuda:0')\n",
            "Epoch: [10][0/885]\tTime 0.735 (0.735)\tData 0.423 (0.423)\tLoss 0.0033 (0.0033)\tError Ratio 0.0429 (0.0429)\n",
            "outputs :  tensor([0.5186], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.5489], device='cuda:0')\n",
            "Epoch: [10][300/885]\tTime 0.342 (0.333)\tData 0.011 (0.007)\tLoss 0.0005 (0.0019)\tError Ratio 0.0413 (0.0554)\n",
            "outputs :  tensor([-1.0719], device='cuda:0', grad_fn=<SelectBackward>) tensor([-1.0576], device='cuda:0')\n",
            "Epoch: [10][600/885]\tTime 0.304 (0.318)\tData 0.004 (0.006)\tLoss 0.0009 (0.0017)\tError Ratio 0.0451 (0.0526)\n",
            "Epoch: [10] Avg Error Ratio 0.052; Average Loss 0.001; Avg Time x Batch 0.309\n",
            "Test: [0/79]\tTime 0.605 (0.605)\tLoss 0.0003 (0.0003)\tError Ratio 0.0310 (0.0310)\n",
            " * Average Error Ratio 0.047; Average Loss 0.002\n",
            "0.046978003019094466 10\n",
            "outputs :  tensor([0.6570], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.6390], device='cuda:0')\n",
            "Epoch: [11][0/885]\tTime 0.774 (0.774)\tData 0.426 (0.426)\tLoss 0.0005 (0.0005)\tError Ratio 0.0335 (0.0335)\n",
            "outputs :  tensor([0.3432], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.3037], device='cuda:0')\n",
            "Epoch: [11][300/885]\tTime 0.285 (0.302)\tData 0.004 (0.007)\tLoss 0.0004 (0.0014)\tError Ratio 0.0332 (0.0511)\n",
            "outputs :  tensor([-0.6651], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.6864], device='cuda:0')\n",
            "Epoch: [11][600/885]\tTime 0.341 (0.300)\tData 0.005 (0.006)\tLoss 0.0006 (0.0012)\tError Ratio 0.0317 (0.0493)\n",
            "Epoch: [11] Avg Error Ratio 0.048; Average Loss 0.001; Avg Time x Batch 0.308\n",
            "Test: [0/79]\tTime 0.567 (0.567)\tLoss 0.0003 (0.0003)\tError Ratio 0.0284 (0.0284)\n",
            " * Average Error Ratio 0.042; Average Loss 0.002\n",
            "0.041970574831962586 11\n",
            "outputs :  tensor([-1.2210], device='cuda:0', grad_fn=<SelectBackward>) tensor([-1.2111], device='cuda:0')\n",
            "Epoch: [12][0/885]\tTime 0.741 (0.741)\tData 0.416 (0.416)\tLoss 0.0005 (0.0005)\tError Ratio 0.0349 (0.0349)\n",
            "outputs :  tensor([-0.1402], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.1272], device='cuda:0')\n",
            "Epoch: [12][300/885]\tTime 0.291 (0.298)\tData 0.004 (0.006)\tLoss 0.0003 (0.0009)\tError Ratio 0.0790 (0.0466)\n",
            "outputs :  tensor([-0.2852], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.2855], device='cuda:0')\n",
            "Epoch: [12][600/885]\tTime 0.305 (0.295)\tData 0.004 (0.006)\tLoss 0.0006 (0.0010)\tError Ratio 0.1200 (0.0444)\n",
            "Epoch: [12] Avg Error Ratio 0.045; Average Loss 0.001; Avg Time x Batch 0.293\n",
            "Test: [0/79]\tTime 0.546 (0.546)\tLoss 0.0003 (0.0003)\tError Ratio 0.0305 (0.0305)\n",
            " * Average Error Ratio 0.049; Average Loss 0.002\n",
            "outputs :  tensor([-0.2505], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.2547], device='cuda:0')\n",
            "Epoch: [13][0/885]\tTime 0.763 (0.763)\tData 0.415 (0.415)\tLoss 0.0006 (0.0006)\tError Ratio 0.0498 (0.0498)\n",
            "outputs :  tensor([-0.3608], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.3764], device='cuda:0')\n",
            "Epoch: [13][300/885]\tTime 0.358 (0.323)\tData 0.011 (0.007)\tLoss 0.0003 (0.0007)\tError Ratio 0.0254 (0.0444)\n",
            "outputs :  tensor([0.5051], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.5491], device='cuda:0')\n",
            "Epoch: [13][600/885]\tTime 0.269 (0.310)\tData 0.004 (0.006)\tLoss 0.0012 (0.0008)\tError Ratio 0.0850 (0.0431)\n",
            "Epoch: [13] Avg Error Ratio 0.042; Average Loss 0.001; Avg Time x Batch 0.302\n",
            "Test: [0/79]\tTime 0.572 (0.572)\tLoss 0.0002 (0.0002)\tError Ratio 0.0261 (0.0261)\n",
            " * Average Error Ratio 0.036; Average Loss 0.001\n",
            "0.03615545980334282 13\n",
            "outputs :  tensor([-0.6448], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.6562], device='cuda:0')\n",
            "Epoch: [14][0/885]\tTime 0.748 (0.748)\tData 0.414 (0.414)\tLoss 0.0004 (0.0004)\tError Ratio 0.0235 (0.0235)\n",
            "outputs :  tensor([-1.1941], device='cuda:0', grad_fn=<SelectBackward>) tensor([-1.1813], device='cuda:0')\n",
            "Epoch: [14][300/885]\tTime 0.275 (0.330)\tData 0.005 (0.007)\tLoss 0.0005 (0.0005)\tError Ratio 0.0393 (0.0392)\n",
            "outputs :  tensor([-0.3094], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.3154], device='cuda:0')\n",
            "Epoch: [14][600/885]\tTime 0.303 (0.309)\tData 0.005 (0.006)\tLoss 0.0007 (0.0006)\tError Ratio 0.0283 (0.0406)\n",
            "Epoch: [14] Avg Error Ratio 0.040; Average Loss 0.001; Avg Time x Batch 0.302\n",
            "Test: [0/79]\tTime 0.561 (0.561)\tLoss 0.0007 (0.0007)\tError Ratio 0.0467 (0.0467)\n",
            " * Average Error Ratio 0.066; Average Loss 0.002\n",
            "outputs :  tensor([-0.1677], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.1312], device='cuda:0')\n",
            "Epoch: [15][0/885]\tTime 0.727 (0.727)\tData 0.400 (0.400)\tLoss 0.0008 (0.0008)\tError Ratio 0.0876 (0.0876)\n",
            "outputs :  tensor([-1.3056], device='cuda:0', grad_fn=<SelectBackward>) tensor([-1.3303], device='cuda:0')\n",
            "Epoch: [15][300/885]\tTime 0.272 (0.293)\tData 0.006 (0.006)\tLoss 0.0003 (0.0007)\tError Ratio 0.0293 (0.0360)\n",
            "outputs :  tensor([0.2277], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.2077], device='cuda:0')\n",
            "Epoch: [15][600/885]\tTime 0.244 (0.291)\tData 0.004 (0.006)\tLoss 0.0004 (0.0006)\tError Ratio 0.0398 (0.0361)\n",
            "Epoch: [15] Avg Error Ratio 0.036; Average Loss 0.001; Avg Time x Batch 0.290\n",
            "Test: [0/79]\tTime 0.549 (0.549)\tLoss 0.0003 (0.0003)\tError Ratio 0.0280 (0.0280)\n",
            " * Average Error Ratio 0.041; Average Loss 0.001\n",
            "outputs :  tensor([0.2103], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.2101], device='cuda:0')\n",
            "Epoch: [16][0/885]\tTime 0.785 (0.785)\tData 0.419 (0.419)\tLoss 0.0007 (0.0007)\tError Ratio 0.0376 (0.0376)\n",
            "outputs :  tensor([-0.2650], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.2558], device='cuda:0')\n",
            "Epoch: [16][300/885]\tTime 0.278 (0.294)\tData 0.004 (0.006)\tLoss 0.0007 (0.0005)\tError Ratio 0.0438 (0.0335)\n",
            "outputs :  tensor([1.1561], device='cuda:0', grad_fn=<SelectBackward>) tensor([1.1572], device='cuda:0')\n",
            "Epoch: [16][600/885]\tTime 0.348 (0.296)\tData 0.004 (0.006)\tLoss 0.0003 (0.0006)\tError Ratio 0.0571 (0.0354)\n",
            "Epoch: [16] Avg Error Ratio 0.037; Average Loss 0.001; Avg Time x Batch 0.306\n",
            "Test: [0/79]\tTime 0.562 (0.562)\tLoss 0.0002 (0.0002)\tError Ratio 0.0214 (0.0214)\n",
            " * Average Error Ratio 0.032; Average Loss 0.001\n",
            "0.032280996507406234 16\n",
            "outputs :  tensor([-0.2856], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.2865], device='cuda:0')\n",
            "Epoch: [17][0/885]\tTime 0.741 (0.741)\tData 0.403 (0.403)\tLoss 0.0003 (0.0003)\tError Ratio 0.0417 (0.0417)\n",
            "outputs :  tensor([1.0772], device='cuda:0', grad_fn=<SelectBackward>) tensor([1.1037], device='cuda:0')\n",
            "Epoch: [17][300/885]\tTime 0.299 (0.292)\tData 0.004 (0.006)\tLoss 0.0007 (0.0005)\tError Ratio 0.0466 (0.0382)\n",
            "outputs :  tensor([-0.0141], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.0371], device='cuda:0')\n",
            "Epoch: [17][600/885]\tTime 0.277 (0.291)\tData 0.007 (0.005)\tLoss 0.0003 (0.0005)\tError Ratio 0.0299 (0.0364)\n",
            "Epoch: [17] Avg Error Ratio 0.036; Average Loss 0.001; Avg Time x Batch 0.290\n",
            "Test: [0/79]\tTime 0.552 (0.552)\tLoss 0.0002 (0.0002)\tError Ratio 0.0242 (0.0242)\n",
            " * Average Error Ratio 0.034; Average Loss 0.001\n",
            "outputs :  tensor([-0.1254], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.1329], device='cuda:0')\n",
            "Epoch: [18][0/885]\tTime 0.745 (0.745)\tData 0.422 (0.422)\tLoss 0.0003 (0.0003)\tError Ratio 0.0283 (0.0283)\n",
            "outputs :  tensor([1.2271], device='cuda:0', grad_fn=<SelectBackward>) tensor([1.2397], device='cuda:0')\n",
            "Epoch: [18][300/885]\tTime 0.278 (0.295)\tData 0.005 (0.006)\tLoss 0.0002 (0.0003)\tError Ratio 0.0363 (0.0331)\n",
            "outputs :  tensor([-0.2787], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.2861], device='cuda:0')\n",
            "Epoch: [18][600/885]\tTime 0.331 (0.296)\tData 0.012 (0.006)\tLoss 0.0002 (0.0004)\tError Ratio 0.0304 (0.0350)\n",
            "Epoch: [18] Avg Error Ratio 0.034; Average Loss 0.000; Avg Time x Batch 0.311\n",
            "Test: [0/79]\tTime 0.573 (0.573)\tLoss 0.0001 (0.0001)\tError Ratio 0.0202 (0.0202)\n",
            " * Average Error Ratio 0.028; Average Loss 0.001\n",
            "0.027778832364082337 18\n",
            "outputs :  tensor([-1.4287], device='cuda:0', grad_fn=<SelectBackward>) tensor([-1.4582], device='cuda:0')\n",
            "Epoch: [19][0/885]\tTime 0.789 (0.789)\tData 0.452 (0.452)\tLoss 0.0002 (0.0002)\tError Ratio 0.0355 (0.0355)\n",
            "outputs :  tensor([-0.3290], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.3163], device='cuda:0')\n",
            "Epoch: [19][300/885]\tTime 0.309 (0.296)\tData 0.005 (0.006)\tLoss 0.0007 (0.0005)\tError Ratio 0.0822 (0.0363)\n",
            "outputs :  tensor([-0.2864], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.2854], device='cuda:0')\n",
            "Epoch: [19][600/885]\tTime 0.279 (0.293)\tData 0.005 (0.006)\tLoss 0.0001 (0.0005)\tError Ratio 0.0462 (0.0350)\n",
            "Epoch: [19] Avg Error Ratio 0.035; Average Loss 0.000; Avg Time x Batch 0.291\n",
            "Test: [0/79]\tTime 0.592 (0.592)\tLoss 0.0003 (0.0003)\tError Ratio 0.0313 (0.0313)\n",
            " * Average Error Ratio 0.039; Average Loss 0.001\n",
            "outputs :  tensor([-3.1066], device='cuda:0', grad_fn=<SelectBackward>) tensor([-3.1486], device='cuda:0')\n",
            "Epoch: [20][0/885]\tTime 0.769 (0.769)\tData 0.420 (0.420)\tLoss 0.0004 (0.0004)\tError Ratio 0.0300 (0.0300)\n",
            "outputs :  tensor([-0.2850], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.2866], device='cuda:0')\n",
            "Epoch: [20][300/885]\tTime 0.281 (0.293)\tData 0.004 (0.006)\tLoss 0.0002 (0.0005)\tError Ratio 0.0208 (0.0340)\n",
            "outputs :  tensor([0.6210], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.6093], device='cuda:0')\n",
            "Epoch: [20][600/885]\tTime 0.280 (0.293)\tData 0.004 (0.005)\tLoss 0.0005 (0.0005)\tError Ratio 0.0407 (0.0337)\n",
            "Epoch: [20] Avg Error Ratio 0.033; Average Loss 0.000; Avg Time x Batch 0.304\n",
            "Test: [0/79]\tTime 0.561 (0.561)\tLoss 0.0002 (0.0002)\tError Ratio 0.0223 (0.0223)\n",
            " * Average Error Ratio 0.032; Average Loss 0.001\n",
            "outputs :  tensor([-0.5697], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.5625], device='cuda:0')\n",
            "Epoch: [21][0/885]\tTime 0.751 (0.751)\tData 0.426 (0.426)\tLoss 0.0002 (0.0002)\tError Ratio 0.0287 (0.0287)\n",
            "outputs :  tensor([0.2504], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.2366], device='cuda:0')\n",
            "Epoch: [21][300/885]\tTime 0.278 (0.294)\tData 0.006 (0.006)\tLoss 0.0003 (0.0004)\tError Ratio 0.0379 (0.0333)\n",
            "outputs :  tensor([0.7737], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.7876], device='cuda:0')\n",
            "Epoch: [21][600/885]\tTime 0.271 (0.292)\tData 0.004 (0.006)\tLoss 0.0002 (0.0005)\tError Ratio 0.0263 (0.0326)\n",
            "Epoch: [21] Avg Error Ratio 0.033; Average Loss 0.000; Avg Time x Batch 0.291\n",
            "Test: [0/79]\tTime 0.537 (0.537)\tLoss 0.0002 (0.0002)\tError Ratio 0.0284 (0.0284)\n",
            " * Average Error Ratio 0.035; Average Loss 0.001\n",
            "outputs :  tensor([-0.4767], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.4958], device='cuda:0')\n",
            "Epoch: [22][0/885]\tTime 0.754 (0.754)\tData 0.427 (0.427)\tLoss 0.0002 (0.0002)\tError Ratio 0.0356 (0.0356)\n",
            "outputs :  tensor([1.1599], device='cuda:0', grad_fn=<SelectBackward>) tensor([1.1577], device='cuda:0')\n",
            "Epoch: [22][300/885]\tTime 0.278 (0.292)\tData 0.006 (0.006)\tLoss 0.0002 (0.0003)\tError Ratio 0.0359 (0.0293)\n",
            "outputs :  tensor([-0.8882], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.9018], device='cuda:0')\n",
            "Epoch: [22][600/885]\tTime 0.316 (0.292)\tData 0.004 (0.005)\tLoss 0.0003 (0.0004)\tError Ratio 0.0478 (0.0301)\n",
            "Epoch: [22] Avg Error Ratio 0.033; Average Loss 0.000; Avg Time x Batch 0.300\n",
            "Test: [0/79]\tTime 0.647 (0.647)\tLoss 0.0001 (0.0001)\tError Ratio 0.0187 (0.0187)\n",
            " * Average Error Ratio 0.025; Average Loss 0.001\n",
            "0.025053411960601808 22\n",
            "outputs :  tensor([0.2582], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.2406], device='cuda:0')\n",
            "Epoch: [23][0/885]\tTime 0.860 (0.860)\tData 0.466 (0.466)\tLoss 0.0002 (0.0002)\tError Ratio 0.0246 (0.0246)\n",
            "outputs :  tensor([1.2375], device='cuda:0', grad_fn=<SelectBackward>) tensor([1.2479], device='cuda:0')\n",
            "Epoch: [23][300/885]\tTime 0.276 (0.295)\tData 0.004 (0.006)\tLoss 0.0003 (0.0005)\tError Ratio 0.0393 (0.0395)\n",
            "outputs :  tensor([0.5305], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.5488], device='cuda:0')\n",
            "Epoch: [23][600/885]\tTime 0.276 (0.291)\tData 0.007 (0.006)\tLoss 0.0006 (0.0005)\tError Ratio 0.0287 (0.0355)\n",
            "Epoch: [23] Avg Error Ratio 0.036; Average Loss 0.000; Avg Time x Batch 0.290\n",
            "Test: [0/79]\tTime 0.562 (0.562)\tLoss 0.0004 (0.0004)\tError Ratio 0.0411 (0.0411)\n",
            " * Average Error Ratio 0.052; Average Loss 0.001\n",
            "outputs :  tensor([2.1252], device='cuda:0', grad_fn=<SelectBackward>) tensor([2.1122], device='cuda:0')\n",
            "Epoch: [24][0/885]\tTime 0.737 (0.737)\tData 0.409 (0.409)\tLoss 0.0005 (0.0005)\tError Ratio 0.0382 (0.0382)\n",
            "outputs :  tensor([-2.3498], device='cuda:0', grad_fn=<SelectBackward>) tensor([-2.3494], device='cuda:0')\n",
            "Epoch: [24][300/885]\tTime 0.305 (0.293)\tData 0.004 (0.006)\tLoss 0.0002 (0.0004)\tError Ratio 0.0245 (0.0331)\n",
            "outputs :  tensor([1.2156], device='cuda:0', grad_fn=<SelectBackward>) tensor([1.2173], device='cuda:0')\n",
            "Epoch: [24][600/885]\tTime 0.277 (0.290)\tData 0.005 (0.005)\tLoss 0.0001 (0.0004)\tError Ratio 0.0176 (0.0326)\n",
            "Epoch: [24] Avg Error Ratio 0.032; Average Loss 0.000; Avg Time x Batch 0.289\n",
            "Test: [0/79]\tTime 0.566 (0.566)\tLoss 0.0001 (0.0001)\tError Ratio 0.0187 (0.0187)\n",
            " * Average Error Ratio 0.024; Average Loss 0.000\n",
            "0.024353033518791197 24\n",
            "outputs :  tensor([-0.2730], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.2849], device='cuda:0')\n",
            "Epoch: [25][0/885]\tTime 0.731 (0.731)\tData 0.414 (0.414)\tLoss 0.0002 (0.0002)\tError Ratio 0.0192 (0.0192)\n",
            "outputs :  tensor([0.5825], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.5781], device='cuda:0')\n",
            "Epoch: [25][300/885]\tTime 0.281 (0.293)\tData 0.007 (0.006)\tLoss 0.0004 (0.0003)\tError Ratio 0.0398 (0.0330)\n",
            "outputs :  tensor([-0.1241], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.1276], device='cuda:0')\n",
            "Epoch: [25][600/885]\tTime 0.340 (0.291)\tData 0.005 (0.006)\tLoss 0.0127 (0.0003)\tError Ratio 0.0408 (0.0306)\n",
            "Epoch: [25] Avg Error Ratio 0.031; Average Loss 0.000; Avg Time x Batch 0.290\n",
            "Test: [0/79]\tTime 0.562 (0.562)\tLoss 0.0003 (0.0003)\tError Ratio 0.0286 (0.0286)\n",
            " * Average Error Ratio 0.040; Average Loss 0.001\n",
            "outputs :  tensor([0.6057], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.6093], device='cuda:0')\n",
            "Epoch: [26][0/885]\tTime 0.794 (0.794)\tData 0.448 (0.448)\tLoss 0.0003 (0.0003)\tError Ratio 0.0315 (0.0315)\n",
            "outputs :  tensor([-1.3736], device='cuda:0', grad_fn=<SelectBackward>) tensor([-1.3618], device='cuda:0')\n",
            "Epoch: [26][300/885]\tTime 0.321 (0.291)\tData 0.005 (0.006)\tLoss 0.0003 (0.0004)\tError Ratio 0.0281 (0.0311)\n",
            "outputs :  tensor([-0.5678], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.5628], device='cuda:0')\n",
            "Epoch: [26][600/885]\tTime 0.274 (0.289)\tData 0.004 (0.006)\tLoss 0.0002 (0.0003)\tError Ratio 0.0223 (0.0307)\n",
            "Epoch: [26] Avg Error Ratio 0.030; Average Loss 0.000; Avg Time x Batch 0.289\n",
            "Test: [0/79]\tTime 0.560 (0.560)\tLoss 0.0001 (0.0001)\tError Ratio 0.0173 (0.0173)\n",
            " * Average Error Ratio 0.023; Average Loss 0.000\n",
            "0.023194108867645263 26\n",
            "outputs :  tensor([1.1298], device='cuda:0', grad_fn=<SelectBackward>) tensor([1.1565], device='cuda:0')\n",
            "Epoch: [27][0/885]\tTime 0.785 (0.785)\tData 0.419 (0.419)\tLoss 0.0002 (0.0002)\tError Ratio 0.0214 (0.0214)\n",
            "outputs :  tensor([-0.2209], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.2262], device='cuda:0')\n",
            "Epoch: [27][300/885]\tTime 0.280 (0.294)\tData 0.007 (0.006)\tLoss 0.0001 (0.0004)\tError Ratio 0.0243 (0.0278)\n",
            "outputs :  tensor([2.5046], device='cuda:0', grad_fn=<SelectBackward>) tensor([2.4831], device='cuda:0')\n",
            "Epoch: [27][600/885]\tTime 0.313 (0.309)\tData 0.004 (0.006)\tLoss 0.0003 (0.0003)\tError Ratio 0.0504 (0.0283)\n",
            "Epoch: [27] Avg Error Ratio 0.028; Average Loss 0.000; Avg Time x Batch 0.302\n",
            "Test: [0/79]\tTime 0.553 (0.553)\tLoss 0.0001 (0.0001)\tError Ratio 0.0165 (0.0165)\n",
            " * Average Error Ratio 0.023; Average Loss 0.000\n",
            "0.022611642488837243 27\n",
            "outputs :  tensor([0.6126], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.6079], device='cuda:0')\n",
            "Epoch: [28][0/885]\tTime 0.763 (0.763)\tData 0.437 (0.437)\tLoss 0.0001 (0.0001)\tError Ratio 0.0146 (0.0146)\n",
            "outputs :  tensor([-0.1792], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.1912], device='cuda:0')\n",
            "Epoch: [28][300/885]\tTime 0.267 (0.295)\tData 0.006 (0.007)\tLoss 0.0004 (0.0003)\tError Ratio 0.0588 (0.0256)\n",
            "outputs :  tensor([-0.1040], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.1083], device='cuda:0')\n",
            "Epoch: [28][600/885]\tTime 0.279 (0.292)\tData 0.004 (0.006)\tLoss 0.0003 (0.0003)\tError Ratio 0.0238 (0.0279)\n",
            "Epoch: [28] Avg Error Ratio 0.028; Average Loss 0.000; Avg Time x Batch 0.290\n",
            "Test: [0/79]\tTime 0.561 (0.561)\tLoss 0.0001 (0.0001)\tError Ratio 0.0166 (0.0166)\n",
            " * Average Error Ratio 0.023; Average Loss 0.000\n",
            "outputs :  tensor([0.2053], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.2087], device='cuda:0')\n",
            "Epoch: [29][0/885]\tTime 0.783 (0.783)\tData 0.424 (0.424)\tLoss 0.0002 (0.0002)\tError Ratio 0.0230 (0.0230)\n",
            "outputs :  tensor([1.1434], device='cuda:0', grad_fn=<SelectBackward>) tensor([1.1340], device='cuda:0')\n",
            "Epoch: [29][300/885]\tTime 0.276 (0.292)\tData 0.008 (0.007)\tLoss 0.0003 (0.0002)\tError Ratio 0.0387 (0.0300)\n",
            "outputs :  tensor([-1.0980], device='cuda:0', grad_fn=<SelectBackward>) tensor([-1.0873], device='cuda:0')\n",
            "Epoch: [29][600/885]\tTime 0.348 (0.301)\tData 0.005 (0.006)\tLoss 0.0001 (0.0003)\tError Ratio 0.0211 (0.0300)\n",
            "Epoch: [29] Avg Error Ratio 0.030; Average Loss 0.000; Avg Time x Batch 0.301\n",
            "Test: [0/79]\tTime 0.547 (0.547)\tLoss 0.0001 (0.0001)\tError Ratio 0.0206 (0.0206)\n",
            " * Average Error Ratio 0.025; Average Loss 0.000\n",
            "outputs :  tensor([0.2740], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.2679], device='cuda:0')\n",
            "Epoch: [30][0/885]\tTime 0.767 (0.767)\tData 0.423 (0.423)\tLoss 0.0001 (0.0001)\tError Ratio 0.0187 (0.0187)\n",
            "outputs :  tensor([-1.5378], device='cuda:0', grad_fn=<SelectBackward>) tensor([-1.5526], device='cuda:0')\n",
            "Epoch: [30][300/885]\tTime 0.289 (0.293)\tData 0.004 (0.006)\tLoss 0.0007 (0.0003)\tError Ratio 0.0867 (0.0276)\n",
            "outputs :  tensor([-0.1330], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.1331], device='cuda:0')\n",
            "Epoch: [30][600/885]\tTime 0.288 (0.290)\tData 0.004 (0.005)\tLoss 0.0002 (0.0003)\tError Ratio 0.0276 (0.0299)\n",
            "Epoch: [30] Avg Error Ratio 0.028; Average Loss 0.000; Avg Time x Batch 0.289\n",
            "Test: [0/79]\tTime 0.541 (0.541)\tLoss 0.0001 (0.0001)\tError Ratio 0.0166 (0.0166)\n",
            " * Average Error Ratio 0.021; Average Loss 0.000\n",
            "0.02146305923461914 30\n",
            "outputs :  tensor([0.6655], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.6711], device='cuda:0')\n",
            "Epoch: [31][0/885]\tTime 0.738 (0.738)\tData 0.412 (0.412)\tLoss 0.0001 (0.0001)\tError Ratio 0.0208 (0.0208)\n",
            "outputs :  tensor([-0.1642], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.1611], device='cuda:0')\n",
            "Epoch: [31][300/885]\tTime 0.277 (0.293)\tData 0.004 (0.006)\tLoss 0.0001 (0.0003)\tError Ratio 0.0183 (0.0300)\n",
            "outputs :  tensor([1.5987], device='cuda:0', grad_fn=<SelectBackward>) tensor([1.5879], device='cuda:0')\n",
            "Epoch: [31][600/885]\tTime 0.239 (0.292)\tData 0.004 (0.005)\tLoss 0.0002 (0.0003)\tError Ratio 0.0195 (0.0290)\n",
            "Epoch: [31] Avg Error Ratio 0.029; Average Loss 0.000; Avg Time x Batch 0.290\n",
            "Test: [0/79]\tTime 0.567 (0.567)\tLoss 0.0001 (0.0001)\tError Ratio 0.0186 (0.0186)\n",
            " * Average Error Ratio 0.022; Average Loss 0.000\n",
            "outputs :  tensor([0.2576], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.2388], device='cuda:0')\n",
            "Epoch: [32][0/885]\tTime 0.750 (0.750)\tData 0.428 (0.428)\tLoss 0.0001 (0.0001)\tError Ratio 0.0195 (0.0195)\n",
            "outputs :  tensor([1.5640], device='cuda:0', grad_fn=<SelectBackward>) tensor([1.5573], device='cuda:0')\n",
            "Epoch: [32][300/885]\tTime 0.281 (0.293)\tData 0.004 (0.006)\tLoss 0.0001 (0.0002)\tError Ratio 0.0215 (0.0247)\n",
            "outputs :  tensor([-0.9670], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.9625], device='cuda:0')\n",
            "Epoch: [32][600/885]\tTime 0.314 (0.291)\tData 0.007 (0.005)\tLoss 0.0002 (0.0002)\tError Ratio 0.0257 (0.0262)\n",
            "Epoch: [32] Avg Error Ratio 0.026; Average Loss 0.000; Avg Time x Batch 0.289\n",
            "Test: [0/79]\tTime 0.559 (0.559)\tLoss 0.0001 (0.0001)\tError Ratio 0.0154 (0.0154)\n",
            " * Average Error Ratio 0.021; Average Loss 0.000\n",
            "0.02070840973854065 32\n",
            "outputs :  tensor([0.1761], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.1782], device='cuda:0')\n",
            "Epoch: [33][0/885]\tTime 0.735 (0.735)\tData 0.419 (0.419)\tLoss 0.0001 (0.0001)\tError Ratio 0.0178 (0.0178)\n",
            "outputs :  tensor([-1.5503], device='cuda:0', grad_fn=<SelectBackward>) tensor([-1.5515], device='cuda:0')\n",
            "Epoch: [33][300/885]\tTime 0.312 (0.291)\tData 0.005 (0.006)\tLoss 0.0001 (0.0002)\tError Ratio 0.0162 (0.0278)\n",
            "outputs :  tensor([-1.9517], device='cuda:0', grad_fn=<SelectBackward>) tensor([-1.9821], device='cuda:0')\n",
            "Epoch: [33][600/885]\tTime 0.280 (0.290)\tData 0.004 (0.006)\tLoss 0.0001 (0.0002)\tError Ratio 0.0267 (0.0278)\n",
            "Epoch: [33] Avg Error Ratio 0.028; Average Loss 0.000; Avg Time x Batch 0.290\n",
            "Test: [0/79]\tTime 0.562 (0.562)\tLoss 0.0001 (0.0001)\tError Ratio 0.0183 (0.0183)\n",
            " * Average Error Ratio 0.023; Average Loss 0.000\n",
            "outputs :  tensor([0.2753], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.2693], device='cuda:0')\n",
            "Epoch: [34][0/885]\tTime 0.757 (0.757)\tData 0.431 (0.431)\tLoss 0.0001 (0.0001)\tError Ratio 0.0169 (0.0169)\n",
            "outputs :  tensor([0.6362], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.6330], device='cuda:0')\n",
            "Epoch: [34][300/885]\tTime 0.330 (0.300)\tData 0.004 (0.006)\tLoss 0.0002 (0.0003)\tError Ratio 0.0137 (0.0238)\n",
            "outputs :  tensor([0.6564], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.6615], device='cuda:0')\n",
            "Epoch: [34][600/885]\tTime 0.302 (0.310)\tData 0.004 (0.006)\tLoss 0.0001 (0.0002)\tError Ratio 0.0186 (0.0250)\n",
            "Epoch: [34] Avg Error Ratio 0.025; Average Loss 0.000; Avg Time x Batch 0.304\n",
            "Test: [0/79]\tTime 0.613 (0.613)\tLoss 0.0003 (0.0003)\tError Ratio 0.0308 (0.0308)\n",
            " * Average Error Ratio 0.044; Average Loss 0.000\n",
            "outputs :  tensor([-0.2488], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.2267], device='cuda:0')\n",
            "Epoch: [35][0/885]\tTime 0.773 (0.773)\tData 0.435 (0.435)\tLoss 0.0003 (0.0003)\tError Ratio 0.0441 (0.0441)\n",
            "outputs :  tensor([0.6466], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.6397], device='cuda:0')\n",
            "Epoch: [35][300/885]\tTime 0.286 (0.292)\tData 0.004 (0.006)\tLoss 0.0001 (0.0002)\tError Ratio 0.0272 (0.0247)\n",
            "outputs :  tensor([-0.2874], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.2864], device='cuda:0')\n",
            "Epoch: [35][600/885]\tTime 0.273 (0.291)\tData 0.007 (0.005)\tLoss 0.0002 (0.0002)\tError Ratio 0.0144 (0.0262)\n",
            "Epoch: [35] Avg Error Ratio 0.026; Average Loss 0.000; Avg Time x Batch 0.290\n",
            "Test: [0/79]\tTime 0.553 (0.553)\tLoss 0.0001 (0.0001)\tError Ratio 0.0146 (0.0146)\n",
            " * Average Error Ratio 0.021; Average Loss 0.000\n",
            "0.02060426117479801 35\n",
            "outputs :  tensor([-0.6855], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.6876], device='cuda:0')\n",
            "Epoch: [36][0/885]\tTime 0.754 (0.754)\tData 0.416 (0.416)\tLoss 0.0001 (0.0001)\tError Ratio 0.0146 (0.0146)\n",
            "outputs :  tensor([1.1916], device='cuda:0', grad_fn=<SelectBackward>) tensor([1.1891], device='cuda:0')\n",
            "Epoch: [36][300/885]\tTime 0.288 (0.294)\tData 0.004 (0.006)\tLoss 0.0001 (0.0003)\tError Ratio 0.0161 (0.0272)\n",
            "outputs :  tensor([0.5485], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.5488], device='cuda:0')\n",
            "Epoch: [36][600/885]\tTime 0.306 (0.308)\tData 0.016 (0.006)\tLoss 0.0002 (0.0002)\tError Ratio 0.0261 (0.0259)\n",
            "Epoch: [36] Avg Error Ratio 0.027; Average Loss 0.000; Avg Time x Batch 0.303\n",
            "Test: [0/79]\tTime 0.551 (0.551)\tLoss 0.0001 (0.0001)\tError Ratio 0.0142 (0.0142)\n",
            " * Average Error Ratio 0.020; Average Loss 0.000\n",
            "0.019996093010902403 36\n",
            "outputs :  tensor([1.5162], device='cuda:0', grad_fn=<SelectBackward>) tensor([1.5044], device='cuda:0')\n",
            "Epoch: [37][0/885]\tTime 0.789 (0.789)\tData 0.431 (0.431)\tLoss 0.0001 (0.0001)\tError Ratio 0.0162 (0.0162)\n",
            "outputs :  tensor([-0.6798], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.6576], device='cuda:0')\n",
            "Epoch: [37][300/885]\tTime 0.278 (0.293)\tData 0.004 (0.006)\tLoss 0.0003 (0.0002)\tError Ratio 0.0343 (0.0291)\n",
            "outputs :  tensor([-0.3208], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.3155], device='cuda:0')\n",
            "Epoch: [37][600/885]\tTime 0.274 (0.291)\tData 0.004 (0.006)\tLoss 0.0002 (0.0002)\tError Ratio 0.0214 (0.0280)\n",
            "Epoch: [37] Avg Error Ratio 0.027; Average Loss 0.000; Avg Time x Batch 0.289\n",
            "Test: [0/79]\tTime 0.549 (0.549)\tLoss 0.0003 (0.0003)\tError Ratio 0.0374 (0.0374)\n",
            " * Average Error Ratio 0.046; Average Loss 0.000\n",
            "outputs :  tensor([-2.0337], device='cuda:0', grad_fn=<SelectBackward>) tensor([-2.0484], device='cuda:0')\n",
            "Epoch: [38][0/885]\tTime 0.778 (0.778)\tData 0.426 (0.426)\tLoss 0.0003 (0.0003)\tError Ratio 0.0407 (0.0407)\n",
            "outputs :  tensor([1.1879], device='cuda:0', grad_fn=<SelectBackward>) tensor([1.1876], device='cuda:0')\n",
            "Epoch: [38][300/885]\tTime 0.310 (0.292)\tData 0.006 (0.006)\tLoss 0.0001 (0.0003)\tError Ratio 0.0174 (0.0235)\n",
            "outputs :  tensor([-0.9141], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.9013], device='cuda:0')\n",
            "Epoch: [38][600/885]\tTime 0.272 (0.290)\tData 0.004 (0.005)\tLoss 0.0001 (0.0002)\tError Ratio 0.0142 (0.0235)\n",
            "Epoch: [38] Avg Error Ratio 0.024; Average Loss 0.000; Avg Time x Batch 0.288\n",
            "Test: [0/79]\tTime 0.555 (0.555)\tLoss 0.0001 (0.0001)\tError Ratio 0.0176 (0.0176)\n",
            " * Average Error Ratio 0.026; Average Loss 0.000\n",
            "outputs :  tensor([0.2334], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.2409], device='cuda:0')\n",
            "Epoch: [39][0/885]\tTime 0.745 (0.745)\tData 0.425 (0.425)\tLoss 0.0001 (0.0001)\tError Ratio 0.0530 (0.0530)\n",
            "outputs :  tensor([3.0974], device='cuda:0', grad_fn=<SelectBackward>) tensor([3.0603], device='cuda:0')\n",
            "Epoch: [39][300/885]\tTime 0.275 (0.291)\tData 0.004 (0.006)\tLoss 0.0002 (0.0003)\tError Ratio 0.0208 (0.0279)\n",
            "outputs :  tensor([-0.6026], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.6036], device='cuda:0')\n",
            "Epoch: [39][600/885]\tTime 0.306 (0.290)\tData 0.005 (0.006)\tLoss 0.0002 (0.0003)\tError Ratio 0.0347 (0.0282)\n",
            "Epoch: [39] Avg Error Ratio 0.030; Average Loss 0.000; Avg Time x Batch 0.289\n",
            "Test: [0/79]\tTime 0.568 (0.568)\tLoss 0.0001 (0.0001)\tError Ratio 0.0211 (0.0211)\n",
            " * Average Error Ratio 0.024; Average Loss 0.000\n",
            "outputs :  tensor([1.5707], device='cuda:0', grad_fn=<SelectBackward>) tensor([1.5580], device='cuda:0')\n",
            "Epoch: [40][0/885]\tTime 0.763 (0.763)\tData 0.426 (0.426)\tLoss 0.0001 (0.0001)\tError Ratio 0.0249 (0.0249)\n",
            "outputs :  tensor([-0.6828], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.7148], device='cuda:0')\n",
            "Epoch: [40][300/885]\tTime 0.309 (0.292)\tData 0.004 (0.006)\tLoss 0.0002 (0.0002)\tError Ratio 0.0256 (0.0236)\n",
            "outputs :  tensor([2.7399], device='cuda:0', grad_fn=<SelectBackward>) tensor([2.7444], device='cuda:0')\n",
            "Epoch: [40][600/885]\tTime 0.304 (0.291)\tData 0.005 (0.005)\tLoss 0.0002 (0.0002)\tError Ratio 0.0528 (0.0228)\n",
            "Epoch: [40] Avg Error Ratio 0.024; Average Loss 0.000; Avg Time x Batch 0.290\n",
            "Test: [0/79]\tTime 0.550 (0.550)\tLoss 0.0002 (0.0002)\tError Ratio 0.0253 (0.0253)\n",
            " * Average Error Ratio 0.035; Average Loss 0.000\n",
            "outputs :  tensor([0.2261], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.2424], device='cuda:0')\n",
            "Epoch: [41][0/885]\tTime 0.736 (0.736)\tData 0.413 (0.413)\tLoss 0.0002 (0.0002)\tError Ratio 0.0432 (0.0432)\n",
            "outputs :  tensor([-0.7233], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.7147], device='cuda:0')\n",
            "Epoch: [41][300/885]\tTime 0.316 (0.336)\tData 0.007 (0.007)\tLoss 0.0001 (0.0003)\tError Ratio 0.0135 (0.0273)\n",
            "outputs :  tensor([-0.6601], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.6254], device='cuda:0')\n",
            "Epoch: [41][600/885]\tTime 0.302 (0.313)\tData 0.005 (0.006)\tLoss 0.0004 (0.0002)\tError Ratio 0.0567 (0.0251)\n",
            "Epoch: [41] Avg Error Ratio 0.025; Average Loss 0.000; Avg Time x Batch 0.304\n",
            "Test: [0/79]\tTime 0.555 (0.555)\tLoss 0.0001 (0.0001)\tError Ratio 0.0136 (0.0136)\n",
            " * Average Error Ratio 0.018; Average Loss 0.000\n",
            "0.018196278405189514 41\n",
            "outputs :  tensor([-0.7320], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.7170], device='cuda:0')\n",
            "Epoch: [42][0/885]\tTime 0.777 (0.777)\tData 0.421 (0.421)\tLoss 0.0001 (0.0001)\tError Ratio 0.0151 (0.0151)\n",
            "outputs :  tensor([-0.2248], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.2246], device='cuda:0')\n",
            "Epoch: [42][300/885]\tTime 0.308 (0.292)\tData 0.005 (0.006)\tLoss 0.0001 (0.0001)\tError Ratio 0.0176 (0.0225)\n",
            "outputs :  tensor([-0.7230], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.7156], device='cuda:0')\n",
            "Epoch: [42][600/885]\tTime 0.300 (0.290)\tData 0.004 (0.006)\tLoss 0.0001 (0.0002)\tError Ratio 0.0157 (0.0280)\n",
            "Epoch: [42] Avg Error Ratio 0.027; Average Loss 0.000; Avg Time x Batch 0.289\n",
            "Test: [0/79]\tTime 0.562 (0.562)\tLoss 0.0001 (0.0001)\tError Ratio 0.0188 (0.0188)\n",
            " * Average Error Ratio 0.022; Average Loss 0.000\n",
            "outputs :  tensor([0.7910], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.7945], device='cuda:0')\n",
            "Epoch: [43][0/885]\tTime 0.729 (0.729)\tData 0.401 (0.401)\tLoss 0.0001 (0.0001)\tError Ratio 0.0148 (0.0148)\n",
            "outputs :  tensor([2.1713], device='cuda:0', grad_fn=<SelectBackward>) tensor([2.1659], device='cuda:0')\n",
            "Epoch: [43][300/885]\tTime 0.348 (0.326)\tData 0.007 (0.007)\tLoss 0.0001 (0.0002)\tError Ratio 0.0373 (0.0200)\n",
            "outputs :  tensor([-0.2591], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.2558], device='cuda:0')\n",
            "Epoch: [43][600/885]\tTime 0.252 (0.307)\tData 0.005 (0.006)\tLoss 0.0001 (0.0002)\tError Ratio 0.0195 (0.0214)\n",
            "Epoch: [43] Avg Error Ratio 0.022; Average Loss 0.000; Avg Time x Batch 0.300\n",
            "Test: [0/79]\tTime 0.555 (0.555)\tLoss 0.0001 (0.0001)\tError Ratio 0.0130 (0.0130)\n",
            " * Average Error Ratio 0.018; Average Loss 0.000\n",
            "0.017996291452646255 43\n",
            "outputs :  tensor([-0.0491], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.0365], device='cuda:0')\n",
            "Epoch: [44][0/885]\tTime 0.784 (0.784)\tData 0.421 (0.421)\tLoss 0.0001 (0.0001)\tError Ratio 0.0243 (0.0243)\n",
            "outputs :  tensor([0.6960], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.7030], device='cuda:0')\n",
            "Epoch: [44][300/885]\tTime 0.324 (0.293)\tData 0.006 (0.006)\tLoss 0.0001 (0.0002)\tError Ratio 0.0245 (0.0251)\n",
            "outputs :  tensor([-0.6520], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.6554], device='cuda:0')\n",
            "Epoch: [44][600/885]\tTime 0.271 (0.290)\tData 0.004 (0.006)\tLoss 0.0001 (0.0002)\tError Ratio 0.0187 (0.0229)\n",
            "Epoch: [44] Avg Error Ratio 0.023; Average Loss 0.000; Avg Time x Batch 0.290\n",
            "Test: [0/79]\tTime 0.551 (0.551)\tLoss 0.0001 (0.0001)\tError Ratio 0.0150 (0.0150)\n",
            " * Average Error Ratio 0.022; Average Loss 0.000\n",
            "outputs :  tensor([-0.1411], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.1322], device='cuda:0')\n",
            "Epoch: [45][0/885]\tTime 0.732 (0.732)\tData 0.396 (0.396)\tLoss 0.0001 (0.0001)\tError Ratio 0.0570 (0.0570)\n",
            "outputs :  tensor([0.6124], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.6098], device='cuda:0')\n",
            "Epoch: [45][300/885]\tTime 0.294 (0.292)\tData 0.007 (0.006)\tLoss 0.0001 (0.0002)\tError Ratio 0.0124 (0.0238)\n",
            "outputs :  tensor([-0.0930], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.1088], device='cuda:0')\n",
            "Epoch: [45][600/885]\tTime 0.271 (0.290)\tData 0.004 (0.005)\tLoss 0.0001 (0.0002)\tError Ratio 0.0163 (0.0233)\n",
            "Epoch: [45] Avg Error Ratio 0.022; Average Loss 0.000; Avg Time x Batch 0.289\n",
            "Test: [0/79]\tTime 0.559 (0.559)\tLoss 0.0001 (0.0001)\tError Ratio 0.0128 (0.0128)\n",
            " * Average Error Ratio 0.017; Average Loss 0.000\n",
            "0.017365003079175947 45\n",
            "outputs :  tensor([0.6739], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.6704], device='cuda:0')\n",
            "Epoch: [46][0/885]\tTime 0.721 (0.721)\tData 0.410 (0.410)\tLoss 0.0001 (0.0001)\tError Ratio 0.0157 (0.0157)\n",
            "outputs :  tensor([0.2156], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.2395], device='cuda:0')\n",
            "Epoch: [46][300/885]\tTime 0.294 (0.291)\tData 0.004 (0.006)\tLoss 0.0001 (0.0003)\tError Ratio 0.0169 (0.0239)\n",
            "outputs :  tensor([1.1251], device='cuda:0', grad_fn=<SelectBackward>) tensor([1.1335], device='cuda:0')\n",
            "Epoch: [46][600/885]\tTime 0.343 (0.290)\tData 0.004 (0.005)\tLoss 0.0002 (0.0002)\tError Ratio 0.0164 (0.0239)\n",
            "Epoch: [46] Avg Error Ratio 0.025; Average Loss 0.000; Avg Time x Batch 0.289\n",
            "Test: [0/79]\tTime 0.540 (0.540)\tLoss 0.0002 (0.0002)\tError Ratio 0.0249 (0.0249)\n",
            " * Average Error Ratio 0.030; Average Loss 0.000\n",
            "outputs :  tensor([-0.5954], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.5969], device='cuda:0')\n",
            "Epoch: [47][0/885]\tTime 0.750 (0.750)\tData 0.409 (0.409)\tLoss 0.0002 (0.0002)\tError Ratio 0.0241 (0.0241)\n",
            "outputs :  tensor([0.2470], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.2417], device='cuda:0')\n",
            "Epoch: [47][300/885]\tTime 0.276 (0.295)\tData 0.005 (0.006)\tLoss 0.0001 (0.0001)\tError Ratio 0.0192 (0.0200)\n",
            "outputs :  tensor([1.1410], device='cuda:0', grad_fn=<SelectBackward>) tensor([1.1347], device='cuda:0')\n",
            "Epoch: [47][600/885]\tTime 0.294 (0.291)\tData 0.004 (0.006)\tLoss 0.0001 (0.0002)\tError Ratio 0.0319 (0.0219)\n",
            "Epoch: [47] Avg Error Ratio 0.024; Average Loss 0.000; Avg Time x Batch 0.292\n",
            "Test: [0/79]\tTime 0.640 (0.640)\tLoss 0.0001 (0.0001)\tError Ratio 0.0126 (0.0126)\n",
            " * Average Error Ratio 0.018; Average Loss 0.000\n",
            "outputs :  tensor([0.2695], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.2693], device='cuda:0')\n",
            "Epoch: [48][0/885]\tTime 0.824 (0.824)\tData 0.430 (0.430)\tLoss 0.0001 (0.0001)\tError Ratio 0.0137 (0.0137)\n",
            "outputs :  tensor([-0.2582], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.2547], device='cuda:0')\n",
            "Epoch: [48][300/885]\tTime 0.281 (0.312)\tData 0.004 (0.007)\tLoss 0.0001 (0.0001)\tError Ratio 0.0171 (0.0203)\n",
            "outputs :  tensor([0.6260], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.6329], device='cuda:0')\n",
            "Epoch: [48][600/885]\tTime 0.272 (0.301)\tData 0.004 (0.006)\tLoss 0.0001 (0.0002)\tError Ratio 0.0214 (0.0223)\n",
            "Epoch: [48] Avg Error Ratio 0.022; Average Loss 0.000; Avg Time x Batch 0.297\n",
            "Test: [0/79]\tTime 0.580 (0.580)\tLoss 0.0001 (0.0001)\tError Ratio 0.0198 (0.0198)\n",
            " * Average Error Ratio 0.028; Average Loss 0.000\n",
            "outputs :  tensor([1.5583], device='cuda:0', grad_fn=<SelectBackward>) tensor([1.5663], device='cuda:0')\n",
            "Epoch: [49][0/885]\tTime 0.747 (0.747)\tData 0.411 (0.411)\tLoss 0.0001 (0.0001)\tError Ratio 0.0218 (0.0218)\n",
            "outputs :  tensor([-0.9137], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.9294], device='cuda:0')\n",
            "Epoch: [49][300/885]\tTime 0.273 (0.293)\tData 0.004 (0.006)\tLoss 0.0001 (0.0001)\tError Ratio 0.0226 (0.0205)\n",
            "outputs :  tensor([0.6244], device='cuda:0', grad_fn=<SelectBackward>) tensor([0.6096], device='cuda:0')\n",
            "Epoch: [49][600/885]\tTime 0.278 (0.291)\tData 0.005 (0.006)\tLoss 0.0002 (0.0002)\tError Ratio 0.0217 (0.0230)\n",
            "Epoch: [49] Avg Error Ratio 0.022; Average Loss 0.000; Avg Time x Batch 0.291\n",
            "Test: [0/79]\tTime 0.552 (0.552)\tLoss 0.0001 (0.0001)\tError Ratio 0.0150 (0.0150)\n",
            " * Average Error Ratio 0.019; Average Loss 0.000\n",
            "Test: [0/79]\tTime 0.586 (0.586)\tLoss 0.0001 (0.0001)\tError Ratio 0.0118 (0.0118)\n",
            " * Average Error Ratio 0.019; Average Loss 0.000\n",
            "0.018672386306524277\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAR8CAYAAAB1xFYrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6ovj/3n2AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x1440 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnoZHO_1jkE2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "00fcfab3-4522-4029-9ee0-b797e360cfe9"
      },
      "source": [
        "print(test_err)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.018672386306524277\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}