{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Project_MPNN_revised_add",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEhovdMpvPSM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "c42d1b5f-b8f0-4eb3-de1a-46c61104820d"
      },
      "source": [
        "#Set google drive\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkG_KLMDw4Y6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2b02e2f7-6317-4a61-e700-e4dba2eb6112"
      },
      "source": [
        "#Install miniconda and rdkit\n",
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!time bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!time conda install -q -y -c conda-forge rdkit\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-16 13:08:11--  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.200.79, 104.18.201.79, 2606:4700::6812:c94f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.200.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 71785000 (68M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-latest-Linux-x86_64.sh’\n",
            "\n",
            "\r          Miniconda   0%[                    ]       0  --.-KB/s               \r         Miniconda3  47%[========>           ]  32.85M   164MB/s               \rMiniconda3-latest-L 100%[===================>]  68.46M   174MB/s    in 0.4s    \n",
            "\n",
            "2019-12-16 13:08:12 (174 MB/s) - ‘Miniconda3-latest-Linux-x86_64.sh’ saved [71785000/71785000]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - asn1crypto==1.2.0=py37_0\n",
            "    - ca-certificates==2019.10.16=0\n",
            "    - certifi==2019.9.11=py37_0\n",
            "    - cffi==1.13.0=py37h2e261b9_0\n",
            "    - chardet==3.0.4=py37_1003\n",
            "    - conda-package-handling==1.6.0=py37h7b6447c_0\n",
            "    - conda==4.7.12=py37_0\n",
            "    - cryptography==2.8=py37h1ba5d50_0\n",
            "    - idna==2.8=py37_0\n",
            "    - libedit==3.1.20181209=hc058e9b_0\n",
            "    - libffi==3.2.1=hd88cf55_4\n",
            "    - libgcc-ng==9.1.0=hdf63c60_0\n",
            "    - libstdcxx-ng==9.1.0=hdf63c60_0\n",
            "    - ncurses==6.1=he6710b0_1\n",
            "    - openssl==1.1.1d=h7b6447c_3\n",
            "    - pip==19.3.1=py37_0\n",
            "    - pycosat==0.6.3=py37h14c3975_0\n",
            "    - pycparser==2.19=py37_0\n",
            "    - pyopenssl==19.0.0=py37_0\n",
            "    - pysocks==1.7.1=py37_0\n",
            "    - python==3.7.4=h265db76_1\n",
            "    - readline==7.0=h7b6447c_5\n",
            "    - requests==2.22.0=py37_0\n",
            "    - ruamel_yaml==0.15.46=py37h14c3975_0\n",
            "    - setuptools==41.4.0=py37_0\n",
            "    - six==1.12.0=py37_0\n",
            "    - sqlite==3.30.0=h7b6447c_0\n",
            "    - tk==8.6.8=hbc83047_0\n",
            "    - tqdm==4.36.1=py_0\n",
            "    - urllib3==1.24.2=py37_0\n",
            "    - wheel==0.33.6=py37_0\n",
            "    - xz==5.2.4=h14c3975_4\n",
            "    - yaml==0.1.7=had09818_2\n",
            "    - zlib==1.2.11=h7b6447c_3\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  asn1crypto         pkgs/main/linux-64::asn1crypto-1.2.0-py37_0\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2019.10.16-0\n",
            "  certifi            pkgs/main/linux-64::certifi-2019.9.11-py37_0\n",
            "  cffi               pkgs/main/linux-64::cffi-1.13.0-py37h2e261b9_0\n",
            "  chardet            pkgs/main/linux-64::chardet-3.0.4-py37_1003\n",
            "  conda              pkgs/main/linux-64::conda-4.7.12-py37_0\n",
            "  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.6.0-py37h7b6447c_0\n",
            "  cryptography       pkgs/main/linux-64::cryptography-2.8-py37h1ba5d50_0\n",
            "  idna               pkgs/main/linux-64::idna-2.8-py37_0\n",
            "  libedit            pkgs/main/linux-64::libedit-3.1.20181209-hc058e9b_0\n",
            "  libffi             pkgs/main/linux-64::libffi-3.2.1-hd88cf55_4\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.1.0-hdf63c60_0\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.1.0-hdf63c60_0\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.1-he6710b0_1\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1d-h7b6447c_3\n",
            "  pip                pkgs/main/linux-64::pip-19.3.1-py37_0\n",
            "  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py37h14c3975_0\n",
            "  pycparser          pkgs/main/linux-64::pycparser-2.19-py37_0\n",
            "  pyopenssl          pkgs/main/linux-64::pyopenssl-19.0.0-py37_0\n",
            "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py37_0\n",
            "  python             pkgs/main/linux-64::python-3.7.4-h265db76_1\n",
            "  readline           pkgs/main/linux-64::readline-7.0-h7b6447c_5\n",
            "  requests           pkgs/main/linux-64::requests-2.22.0-py37_0\n",
            "  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.46-py37h14c3975_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-41.4.0-py37_0\n",
            "  six                pkgs/main/linux-64::six-1.12.0-py37_0\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.30.0-h7b6447c_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.8-hbc83047_0\n",
            "  tqdm               pkgs/main/noarch::tqdm-4.36.1-py_0\n",
            "  urllib3            pkgs/main/linux-64::urllib3-1.24.2-py37_0\n",
            "  wheel              pkgs/main/linux-64::wheel-0.33.6-py37_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.4-h14c3975_4\n",
            "  yaml               pkgs/main/linux-64::yaml-0.1.7-had09818_2\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3\n",
            "\n",
            "\n",
            "Preparing transaction: | \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "\n",
            "real\t0m12.611s\n",
            "user\t0m6.887s\n",
            "sys\t0m2.600s\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - rdkit\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    boost-1.70.0               |   py37h9de70de_1         337 KB  conda-forge\n",
            "    boost-cpp-1.70.0           |       h8e57a91_2        21.1 MB  conda-forge\n",
            "    bzip2-1.0.8                |       h516909a_2         396 KB  conda-forge\n",
            "    ca-certificates-2019.11.28 |       hecc5488_0         145 KB  conda-forge\n",
            "    cairo-1.16.0               |    hfb77d84_1002         1.5 MB  conda-forge\n",
            "    certifi-2019.11.28         |           py37_0         148 KB  conda-forge\n",
            "    conda-4.8.0                |           py37_0         3.0 MB  conda-forge\n",
            "    fontconfig-2.13.1          |    h86ecdb6_1001         340 KB  conda-forge\n",
            "    freetype-2.10.0            |       he983fc9_1         884 KB  conda-forge\n",
            "    gettext-0.19.8.1           |    hc5be6a0_1002         3.6 MB  conda-forge\n",
            "    glib-2.58.3                |py37h6f030ca_1002         3.3 MB  conda-forge\n",
            "    icu-64.2                   |       he1b5a44_1        12.6 MB  conda-forge\n",
            "    jpeg-9c                    |    h14c3975_1001         251 KB  conda-forge\n",
            "    libblas-3.8.0              |      14_openblas          10 KB  conda-forge\n",
            "    libcblas-3.8.0             |      14_openblas          10 KB  conda-forge\n",
            "    libgfortran-ng-7.3.0       |       hdf63c60_2         1.7 MB  conda-forge\n",
            "    libiconv-1.15              |    h516909a_1005         2.0 MB  conda-forge\n",
            "    liblapack-3.8.0            |      14_openblas          10 KB  conda-forge\n",
            "    libopenblas-0.3.7          |       h5ec1e0e_5         7.6 MB  conda-forge\n",
            "    libpng-1.6.37              |       hed695b0_0         343 KB  conda-forge\n",
            "    libtiff-4.1.0              |       hc3755c2_1         609 KB  conda-forge\n",
            "    libuuid-2.32.1             |    h14c3975_1000          26 KB  conda-forge\n",
            "    libxcb-1.13                |    h14c3975_1002         396 KB  conda-forge\n",
            "    libxml2-2.9.10             |       hee79883_0         1.3 MB  conda-forge\n",
            "    lz4-c-1.8.3                |    he1b5a44_1001         187 KB  conda-forge\n",
            "    numpy-1.17.3               |   py37h95a1406_0         5.1 MB  conda-forge\n",
            "    olefile-0.46               |             py_0          31 KB  conda-forge\n",
            "    openssl-1.1.1d             |       h516909a_0         2.1 MB  conda-forge\n",
            "    pandas-0.25.3              |   py37hb3f55d8_0        11.4 MB  conda-forge\n",
            "    pcre-8.43                  |       he1b5a44_0         257 KB  conda-forge\n",
            "    pillow-6.2.1               |   py37h34e0f95_0         643 KB\n",
            "    pixman-0.38.0              |    h516909a_1003         594 KB  conda-forge\n",
            "    pthread-stubs-0.4          |    h14c3975_1001           5 KB  conda-forge\n",
            "    pycairo-1.18.2             |   py37h438ddbb_0          77 KB  conda-forge\n",
            "    python-dateutil-2.8.1      |             py_0         220 KB  conda-forge\n",
            "    pytz-2019.3                |             py_0         237 KB  conda-forge\n",
            "    rdkit-2019.09.2            |   py37hb31dc5d_0        23.8 MB  conda-forge\n",
            "    xorg-kbproto-1.0.7         |    h14c3975_1002          26 KB  conda-forge\n",
            "    xorg-libice-1.0.10         |       h516909a_0          57 KB  conda-forge\n",
            "    xorg-libsm-1.2.3           |    h84519dc_1000          25 KB  conda-forge\n",
            "    xorg-libx11-1.6.9          |       h516909a_0         918 KB  conda-forge\n",
            "    xorg-libxau-1.0.9          |       h14c3975_0          13 KB  conda-forge\n",
            "    xorg-libxdmcp-1.1.3        |       h516909a_0          18 KB  conda-forge\n",
            "    xorg-libxext-1.3.4         |       h516909a_0          51 KB  conda-forge\n",
            "    xorg-libxrender-0.9.10     |    h516909a_1002          31 KB  conda-forge\n",
            "    xorg-renderproto-0.11.1    |    h14c3975_1002           8 KB  conda-forge\n",
            "    xorg-xextproto-7.3.0       |    h14c3975_1002          27 KB  conda-forge\n",
            "    xorg-xproto-7.0.31         |    h14c3975_1007          72 KB  conda-forge\n",
            "    zstd-1.4.4                 |       h3b9ef0a_1         989 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       108.4 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  boost              conda-forge/linux-64::boost-1.70.0-py37h9de70de_1\n",
            "  boost-cpp          conda-forge/linux-64::boost-cpp-1.70.0-h8e57a91_2\n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h516909a_2\n",
            "  cairo              conda-forge/linux-64::cairo-1.16.0-hfb77d84_1002\n",
            "  fontconfig         conda-forge/linux-64::fontconfig-2.13.1-h86ecdb6_1001\n",
            "  freetype           conda-forge/linux-64::freetype-2.10.0-he983fc9_1\n",
            "  gettext            conda-forge/linux-64::gettext-0.19.8.1-hc5be6a0_1002\n",
            "  glib               conda-forge/linux-64::glib-2.58.3-py37h6f030ca_1002\n",
            "  icu                conda-forge/linux-64::icu-64.2-he1b5a44_1\n",
            "  jpeg               conda-forge/linux-64::jpeg-9c-h14c3975_1001\n",
            "  libblas            conda-forge/linux-64::libblas-3.8.0-14_openblas\n",
            "  libcblas           conda-forge/linux-64::libcblas-3.8.0-14_openblas\n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-7.3.0-hdf63c60_2\n",
            "  libiconv           conda-forge/linux-64::libiconv-1.15-h516909a_1005\n",
            "  liblapack          conda-forge/linux-64::liblapack-3.8.0-14_openblas\n",
            "  libopenblas        conda-forge/linux-64::libopenblas-0.3.7-h5ec1e0e_5\n",
            "  libpng             conda-forge/linux-64::libpng-1.6.37-hed695b0_0\n",
            "  libtiff            conda-forge/linux-64::libtiff-4.1.0-hc3755c2_1\n",
            "  libuuid            conda-forge/linux-64::libuuid-2.32.1-h14c3975_1000\n",
            "  libxcb             conda-forge/linux-64::libxcb-1.13-h14c3975_1002\n",
            "  libxml2            conda-forge/linux-64::libxml2-2.9.10-hee79883_0\n",
            "  lz4-c              conda-forge/linux-64::lz4-c-1.8.3-he1b5a44_1001\n",
            "  numpy              conda-forge/linux-64::numpy-1.17.3-py37h95a1406_0\n",
            "  olefile            conda-forge/noarch::olefile-0.46-py_0\n",
            "  pandas             conda-forge/linux-64::pandas-0.25.3-py37hb3f55d8_0\n",
            "  pcre               conda-forge/linux-64::pcre-8.43-he1b5a44_0\n",
            "  pillow             pkgs/main/linux-64::pillow-6.2.1-py37h34e0f95_0\n",
            "  pixman             conda-forge/linux-64::pixman-0.38.0-h516909a_1003\n",
            "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-h14c3975_1001\n",
            "  pycairo            conda-forge/linux-64::pycairo-1.18.2-py37h438ddbb_0\n",
            "  python-dateutil    conda-forge/noarch::python-dateutil-2.8.1-py_0\n",
            "  pytz               conda-forge/noarch::pytz-2019.3-py_0\n",
            "  rdkit              conda-forge/linux-64::rdkit-2019.09.2-py37hb31dc5d_0\n",
            "  xorg-kbproto       conda-forge/linux-64::xorg-kbproto-1.0.7-h14c3975_1002\n",
            "  xorg-libice        conda-forge/linux-64::xorg-libice-1.0.10-h516909a_0\n",
            "  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.3-h84519dc_1000\n",
            "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.6.9-h516909a_0\n",
            "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.9-h14c3975_0\n",
            "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.3-h516909a_0\n",
            "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.4-h516909a_0\n",
            "  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.10-h516909a_1002\n",
            "  xorg-renderproto   conda-forge/linux-64::xorg-renderproto-0.11.1-h14c3975_1002\n",
            "  xorg-xextproto     conda-forge/linux-64::xorg-xextproto-7.3.0-h14c3975_1002\n",
            "  xorg-xproto        conda-forge/linux-64::xorg-xproto-7.0.31-h14c3975_1007\n",
            "  zstd               conda-forge/linux-64::zstd-1.4.4-h3b9ef0a_1\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates    pkgs/main::ca-certificates-2019.10.16~ --> conda-forge::ca-certificates-2019.11.28-hecc5488_0\n",
            "  certifi               pkgs/main::certifi-2019.9.11-py37_0 --> conda-forge::certifi-2019.11.28-py37_0\n",
            "  conda                      pkgs/main::conda-4.7.12-py37_0 --> conda-forge::conda-4.8.0-py37_0\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  openssl              pkgs/main::openssl-1.1.1d-h7b6447c_3 --> conda-forge::openssl-1.1.1d-h516909a_0\n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "\n",
            "real\t0m34.607s\n",
            "user\t0m29.029s\n",
            "sys\t0m3.192s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkEa1uSP-8JT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl\n",
        "# !pip3 install torchvision\n",
        "# ! pip install --verbose --no-cache-dir torch-scatter\n",
        "# ! pip install --verbose --no-cache-dir torch-sparse\n",
        "# ! pip install --verbose --no-cache-dir torch-cluster\n",
        "# ! pip install --verbose --no-cache-dir torch-spline-conv\n",
        "# ! pip install torch-geometric\n",
        "\n",
        "#!pip install tensorboard_logger\n",
        "import numpy as np\n",
        "from numpy import linalg\n",
        "import networkx as nx\n",
        "import torch\n",
        "import time\n",
        "import random\n",
        "import copy\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torch.optim.lr_scheduler as lrs\n",
        "import math\n",
        "\n",
        "import rdkit\n",
        "from rdkit.Chem import AllChem \n",
        "from rdkit import Chem\n",
        "from rdkit import rdBase\n",
        "from rdkit.Chem.rdchem import HybridizationType\n",
        "from rdkit import RDConfig\n",
        "from rdkit.Chem import ChemicalFeatures\n",
        "from rdkit.Chem.rdchem import BondType\n",
        "from rdkit.Chem.rdMolTransforms import GetBondLength\n",
        "\n",
        "import os\n",
        "from os import listdir\n",
        "import os.path as osp\n",
        "from os.path import isfile, join\n",
        "\n",
        "from six.moves import urllib\n",
        "import errno\n",
        "import tarfile\n",
        "import tarfile\n",
        "import multiprocessing\n",
        "from joblib import Parallel, delayed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKUkVm4QOb9A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e0dfb915-6ceb-4198-96ea-3e86afb2901c"
      },
      "source": [
        "#Process data set\n",
        "def coalesce(index, value):\n",
        "    n = index.max().item() + 1\n",
        "    row, col = index\n",
        "    unique, inv = torch.unique(row * n + col, sorted=True, return_inverse=True)\n",
        "\n",
        "    perm = torch.arange(inv.size(0), dtype=inv.dtype, device=inv.device)\n",
        "    perm = inv.new_empty(unique.size(0)).scatter_(0, inv, perm)\n",
        "    index = torch.stack([row[perm], col[perm]], dim=0)\n",
        "    value = value[perm]\n",
        "\n",
        "    return index, value\n",
        "\n",
        "def data_process():\n",
        "    \n",
        "  path = '/content/gdrive/My Drive/QM9'\n",
        "  suppl = Chem.SDMolSupplier('{}/gdb9.sdf'.format(path))\n",
        "\n",
        "  with open('{}/gdb9.sdf.csv'.format(path), 'r') as f:\n",
        "      target = f.read().split('\\n')[1:-1]\n",
        "      n_target = []\n",
        "      for line in target:\n",
        "        x = line.split(',')\n",
        "        n_target.append([float(x[11])])\n",
        "      target = n_target\n",
        "      #target = [[float(x) for x in line.split(',')[6, 7, 13, 14]] for line in target]\n",
        "      #target = torch.tensor(target, dtype=torch.float)\n",
        "\n",
        "  fdef_name = os.path.join(RDConfig.RDDataDir, 'BaseFeatures.fdef')\n",
        "  factory = ChemicalFeatures.BuildFeatureFactory(fdef_name)\n",
        "  data_list = []\n",
        "\n",
        "  for i, mol in enumerate(suppl):\n",
        "    if mol is None:\n",
        "        continue\n",
        "\n",
        "    text = suppl.GetItemText(i)\n",
        "    \n",
        "    num_hs = []\n",
        "    for atom in mol.GetAtoms():\n",
        "        num_hs.append(atom.GetTotalNumHs())\n",
        "\n",
        "    mol = Chem.AddHs(mol)\n",
        "    feats = factory.GetFeaturesForMol(mol)\n",
        "\n",
        "    H_type = []\n",
        "    C_type = []\n",
        "    N_type = []\n",
        "    O_type = []\n",
        "    F_type = []\n",
        "    atomic_number = []\n",
        "    sp = []\n",
        "    sp2 = []\n",
        "    sp3 = []\n",
        "    aromatic = []\n",
        "    acceptor = []\n",
        "    donor = []\n",
        "\n",
        "    # Example 130669 has an error and yields a different number of atoms.\n",
        "    # We discard it.\n",
        "    if i == 130669:\n",
        "        continue\n",
        "\n",
        "    num_atoms = mol.GetNumAtoms()\n",
        "\n",
        "    if i%10000 is 0: print(i)\n",
        "    \n",
        "    pos = text.split('\\n')[4:4 + num_atoms]\n",
        "    pos = [[float(x) for x in line.split()[:3]] for line in pos]\n",
        "\n",
        "    for j in range(num_atoms):\n",
        "        atom = mol.GetAtomWithIdx(j)\n",
        "        symbol = atom.GetSymbol()\n",
        "        H_type.append(1 if symbol == 'H' else 0)\n",
        "        C_type.append(1 if symbol == 'C' else 0)\n",
        "        N_type.append(1 if symbol == 'N' else 0)\n",
        "        O_type.append(1 if symbol == 'O' else 0)\n",
        "        F_type.append(1 if symbol == 'F' else 0)\n",
        "        atomic_number.append(atom.GetAtomicNum())\n",
        "        hybridization = atom.GetHybridization()\n",
        "        sp.append(1 if hybridization == HybridizationType.SP else 0)\n",
        "        sp2.append(1 if hybridization == HybridizationType.SP2 else 0)\n",
        "        sp3.append(1 if hybridization == HybridizationType.SP3 else 0)\n",
        "        aromatic.append(1 if atom.GetIsAromatic() else 0)\n",
        "        acceptor.append(0)\n",
        "        donor.append(0)\n",
        "\n",
        "        if symbol == 'H':\n",
        "            num_hs.insert(j, 0)\n",
        "\n",
        "    for j in range(0, len(feats)):\n",
        "        if feats[j].GetFamily() == 'Donor':\n",
        "            node_list = feats[j].GetAtomIds()\n",
        "            for j in node_list:\n",
        "                donor[j] = 1\n",
        "        elif feats[j].GetFamily() == 'Acceptor':\n",
        "            node_list = feats[j].GetAtomIds()\n",
        "            for j in node_list:\n",
        "                acceptor[j] = 1\n",
        "\n",
        "    x = [\n",
        "        H_type, C_type, N_type, O_type, F_type, atomic_number, acceptor, donor,\n",
        "        aromatic, sp, sp2, sp3, num_hs\n",
        "    ]\n",
        "    x = np.asarray(x).transpose()\n",
        "    pos = torch.tensor(pos, dtype=torch.float).numpy()\n",
        "    y = np.asarray(target[i])\n",
        "\n",
        "    chem, raw, bins = [], [], []\n",
        "    step = (6-2)/8.0\n",
        "    start = 2\n",
        "\n",
        "    for v_i in range(0, num_atoms):\n",
        "          for v_j in range(0, num_atoms):\n",
        "              e_ij = mol.GetBondBetweenAtoms(v_i, v_j)\n",
        "\n",
        "              feat = []\n",
        "\n",
        "              if e_ij is not None :\n",
        "                bond_type = e_ij.GetBondType()\n",
        "                feat = [int(bond_type == x) for x in [rdkit.Chem.rdchem.BondType.SINGLE, rdkit.Chem.rdchem.BondType.DOUBLE,\n",
        "                                                              rdkit.Chem.rdchem.BondType.TRIPLE, rdkit.Chem.rdchem.BondType.AROMATIC]]\n",
        "              \n",
        "              else:\n",
        "                feat = [0, 0, 0, 0]\n",
        "                \n",
        "              dist = np.linalg.norm(pos[v_i]-pos[v_j])\n",
        "              bin_feat = copy.deepcopy(feat)\n",
        "              \n",
        "              b = 9\n",
        "              dist_bin = [0 for bin_iter in range(10)]\n",
        "              for k in range(0, 9):\n",
        "                  if dist < (start+k*step):\n",
        "                      b = k\n",
        "                      break\n",
        "              \n",
        "              dist_bin[b] = 1\n",
        "              bin_feat = bin_feat + dist_bin\n",
        "              bins.append(bin_feat)\n",
        "\n",
        "    size = (num_atoms, num_atoms, -1)\n",
        "\n",
        "    chem = np.asarray(chem).reshape(size)\n",
        "    raw = np.asarray(raw).reshape(size)\n",
        "    bins = np.asarray(bins).reshape(size)\n",
        "\n",
        "    data_list.append({\n",
        "        'x': torch.tensor(x),\n",
        "        'y': torch.tensor(y),\n",
        "        'bins': torch.tensor(bins),\n",
        "    })\n",
        "\n",
        "    \n",
        "  torch.save(data_list, '/content/gdrive/My Drive/QM9/qm9_u0.pt')\n",
        "\n",
        "#data_process()\n",
        "\n",
        "qm9 = torch.load('/content/gdrive/My Drive/QM9/qm9_u0.pt')\n",
        "print(qm9[-1])\n",
        "print(len(qm9))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'x': tensor([[0, 1, 0, 0, 0, 6, 0, 0, 0, 0, 0, 1, 2],\n",
            "        [0, 0, 1, 0, 0, 7, 0, 1, 0, 0, 0, 1, 1],\n",
            "        [0, 1, 0, 0, 0, 6, 0, 0, 0, 0, 0, 1, 1],\n",
            "        [0, 1, 0, 0, 0, 6, 0, 0, 0, 0, 0, 1, 1],\n",
            "        [0, 1, 0, 0, 0, 6, 0, 0, 0, 0, 0, 1, 1],\n",
            "        [0, 0, 0, 1, 0, 8, 1, 0, 0, 0, 0, 1, 0],\n",
            "        [0, 1, 0, 0, 0, 6, 0, 0, 0, 0, 0, 1, 0],\n",
            "        [0, 1, 0, 0, 0, 6, 0, 0, 0, 0, 0, 1, 1],\n",
            "        [0, 1, 0, 0, 0, 6, 0, 0, 0, 0, 0, 1, 1],\n",
            "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]]), 'y': tensor([-400.6331], dtype=torch.float64), 'bins': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [1, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 1]],\n",
            "\n",
            "        [[1, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [1, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 1]],\n",
            "\n",
            "        [[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [1, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 1]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 1]],\n",
            "\n",
            "        [[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 1]],\n",
            "\n",
            "        [[0, 0, 0,  ..., 0, 0, 1],\n",
            "         [0, 0, 0,  ..., 0, 0, 1],\n",
            "         [0, 0, 0,  ..., 0, 0, 1],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 1],\n",
            "         [0, 0, 0,  ..., 0, 0, 1],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]]])}\n",
            "133246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1kAK_h6hSRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Qm9(data.Dataset):\n",
        "\n",
        "    # Constructor\n",
        "    def __init__(self, data_list, ids, target_transform=None, e_representation='raw_distance'):\n",
        "        self.data_list = data_list\n",
        "        self.ids = ids\n",
        "        self.target_transform = target_transform\n",
        "        self.e_representation = e_representation\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        g = self.data_list[self.ids[index]]\n",
        "        h = g['x']\n",
        "        e = g['bins']\n",
        "        target = g['y']\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return (h, e, target)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def set_target_transform(self, target_transform):\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def get_statics(self):\n",
        "\n",
        "        targets = []\n",
        "        for index in range(len(self.ids)):\n",
        "          targets.append(self.data_list[self.ids[index]]['y'])\n",
        "        targets = torch.stack(targets)\n",
        "\n",
        "        return torch.mean(targets, dim=0), torch.std(targets, dim=0)\n",
        "\n",
        "def collate_g(batch):\n",
        "\n",
        "    batch_sizes = np.max(np.array([h.size(0) for (h, e, target) in batch]))\n",
        "\n",
        "    h = np.zeros((len(batch), batch_sizes, 13))\n",
        "    e = np.zeros((len(batch), batch_sizes, batch_sizes, 14))\n",
        "    #target = np.zeros((len(batch), 4))\n",
        "    target = np.zeros((len(batch), 1))\n",
        "\n",
        "    for i in range(len(batch)):\n",
        "\n",
        "        num_nodes = batch[i][0].size(0)\n",
        "        h[i, 0:num_nodes, :] = batch[i][0]\n",
        "        e[i, 0:num_nodes, 0:num_nodes, :] = batch[i][1]\n",
        "\n",
        "        # Target\n",
        "        target[i, :] = batch[i][2]\n",
        "\n",
        "\n",
        "    h = torch.FloatTensor(h)\n",
        "    e = torch.FloatTensor(e)\n",
        "    target = torch.FloatTensor(target)\n",
        "    \n",
        "    return h, e, target\n",
        "\n",
        "def normalize_data(data, mean, std):\n",
        "    data_norm = (data-mean)/std\n",
        "    return data_norm\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPq1p3QR89Dc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NNet(nn.Module):\n",
        "\n",
        "    def __init__(self, n_in, n_out, hlayers=(128, 256, 128)):\n",
        "        super(NNet, self).__init__()\n",
        "        self.n_hlayers = len(hlayers)\n",
        "        self.fcs = nn.ModuleList([nn.Linear(n_in, hlayers[i]) if i == 0 else\n",
        "                                  nn.Linear(hlayers[i-1], n_out) if i == self.n_hlayers else\n",
        "                                  nn.Linear(hlayers[i-1], hlayers[i]) for i in range(self.n_hlayers+1)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i in range(self.n_hlayers):\n",
        "            x = F.relu(self.fcs[i](x))\n",
        "        x = self.fcs[-1](x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3baQH8Fkso6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Set2Set(nn.Module): \n",
        "    def __init__(self, input_dim, M, num_layers=1):\n",
        "        super(Set2Set, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = input_dim*2\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm_output_dim = input_dim\n",
        "        self.lstm = nn.LSTM(input_dim*2, input_dim, num_layers=num_layers, batch_first=True)\n",
        "        self.M = M\n",
        "\n",
        "        self.pred = nn.Linear(input_dim*2, input_dim)\n",
        "        self.act = nn.ReLU()\n",
        "\n",
        "    def forward(self, embedding):\n",
        "        batch_size = embedding.size()[0]\n",
        "        n = embedding.size()[1]\n",
        "\n",
        "        hidden = (torch.zeros(self.num_layers, batch_size, self.lstm_output_dim).cuda(),\n",
        "                  torch.zeros(self.num_layers, batch_size, self.lstm_output_dim).cuda())\n",
        "\n",
        "        q_star = torch.zeros(batch_size, 1, self.hidden_dim).cuda()\n",
        "\n",
        "        for i in range(self.M):\n",
        "            q, hidden = self.lstm(q_star, hidden)\n",
        "            e = embedding @ torch.transpose(q, 1, 2)\n",
        "            a = nn.Softmax(dim=1)(e)\n",
        "            r = torch.sum(a * embedding, dim=1, keepdim=True)\n",
        "            q_star = torch.cat((q, r), dim=2)\n",
        "        q_star = torch.squeeze(q_star, dim=1)\n",
        "        out = self.act(self.pred(q_star))\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ9v_Xy69TmR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def train(train_loader, model, criterion, optimizer, epoch, evaluation, logger=None):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    error_ratio = AverageMeter()\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "\n",
        "    loss_list = []\n",
        "    err_list = []\n",
        "\n",
        "    for i, (h, e, target) in enumerate(train_loader):\n",
        "\n",
        "        # Prepare input data\n",
        "        h, e, target = h.cuda(), e.cuda(), target.cuda()\n",
        "\n",
        "        # Measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Compute output\n",
        "        output = model(h, e)\n",
        "        train_loss = criterion(output, target)\n",
        "        eval_val = evaluation(output, target)\n",
        "\n",
        "        loss_list.append(train_loss.item())\n",
        "        err_list.append(eval_val.item())\n",
        "\n",
        "        # Logs\n",
        "        losses.update(train_loss.item(), h.size(0))\n",
        "        error_ratio.update(eval_val, h.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        train_loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        # Measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % 300 == 0:\n",
        "\n",
        "          print('outputs : ', output[0], target[0])\n",
        "\n",
        "          print('Epoch: [{0}][{1}/{2}]\\t'\n",
        "                'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
        "                'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                'Error Ratio {err.val:.4f} ({err.avg:.4f})'\n",
        "                .format(epoch, i, len(train_loader), batch_time=batch_time,\n",
        "                        data_time=data_time, loss=losses, err=error_ratio))\n",
        "        \n",
        "    if logger is not None:\n",
        "      logger.log_value('train_epoch_loss', losses.avg)\n",
        "      logger.log_value('train_epoch_error_ratio', error_ratio.avg)\n",
        "\n",
        "    print('Epoch: [{0}] Avg Error Ratio {err.avg:.3f}; Average Loss {loss.avg:.3f}; Avg Time x Batch {b_time.avg:.3f}'\n",
        "          .format(epoch, err=error_ratio, loss=losses, b_time=batch_time))\n",
        "    \n",
        "    return loss_list, err_list\n",
        "\n",
        "\n",
        "def validate(val_loader, model, criterion, evaluation, logger=None):\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    error_ratio = AverageMeter()\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (h, e, target) in enumerate(val_loader):\n",
        "\n",
        "        # Prepare input data\n",
        "        h, e, target = h.cuda(), e.cuda(), target.cuda()\n",
        "\n",
        "        # Compute output\n",
        "        output = model(h, e)\n",
        "\n",
        "        # Logs\n",
        "        losses.update(criterion(output, target).item(), h.size(0))\n",
        "        error_ratio.update(evaluation(output, target).item(), h.size(0))\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % 300 == 0:\n",
        "\n",
        "          print('Test: [{0}/{1}]\\t'\n",
        "                'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                'Error Ratio {err.val:.4f} ({err.avg:.4f})'\n",
        "                .format(i, len(val_loader), batch_time=batch_time,\n",
        "                        loss=losses, err=error_ratio))\n",
        "\n",
        "    print(' * Average Error Ratio {err.avg:.3f}; Average Loss {loss.avg:.3f}'\n",
        "          .format(err=error_ratio, loss=losses))\n",
        "\n",
        "    if logger is not None:\n",
        "        logger.log_value('test_epoch_loss', losses.avg)\n",
        "        logger.log_value('test_epoch_error_ratio', error_ratio.avg)\n",
        "\n",
        "    return error_ratio.avg, losses.avg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__Ms-m9D_E7_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c20de2d7-4a6a-4ee8-8382-5101cbee826d"
      },
      "source": [
        "print('Prepare files')\n",
        "\n",
        "idx = np.random.permutation(133245)\n",
        "idx = idx.tolist()\n",
        "valid_ids = idx[0:10000]\n",
        "test_ids = idx[10000:20000]\n",
        "train_ids = idx[20000:]\n",
        "\n",
        "# reduce num of dataset for debugging\n",
        "# idx = np.random.permutation(10000)\n",
        "# idx = idx.tolist()\n",
        "# valid_ids = idx[0:1000]\n",
        "# test_ids = idx[1000:2000]\n",
        "# train_ids = idx[2000:]\n",
        "\n",
        "data_train = Qm9(qm9, train_ids)\n",
        "data_valid = Qm9(qm9, valid_ids)\n",
        "data_test = Qm9(qm9, test_ids)\n",
        "\n",
        "train_mean, train_std = data_train.get_statics()\n",
        "\n",
        "data_train.set_target_transform(lambda x: normalize_data(x, train_mean, train_std))\n",
        "data_valid.set_target_transform(lambda x: normalize_data(x, train_mean, train_std))\n",
        "data_test.set_target_transform(lambda x: normalize_data(x, train_mean, train_std))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(data_train,\n",
        "                                            batch_size=128, shuffle=True,\n",
        "                                            collate_fn=collate_g,\n",
        "                                            num_workers=0)\n",
        "valid_loader = torch.utils.data.DataLoader(data_valid,\n",
        "                                            batch_size=128, collate_fn=collate_g,\n",
        "                                            num_workers=0)\n",
        "test_loader = torch.utils.data.DataLoader(data_test,\n",
        "                                          batch_size=128, collate_fn=collate_g,\n",
        "                                          num_workers=0)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prepare files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmNfz3PZj_fF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MessageFunction(nn.Module):\n",
        "  def __init__(self, n_bond, n_atoms):\n",
        "    super(MessageFunction, self).__init__()\n",
        "    self.fcs = NNet(n_in=n_bond, n_out=(n_atoms*n_atoms), hlayers=[128])\n",
        "    #self.fcs = nn.Linear(n_bond, n_atoms*n_atoms)\n",
        "    self.n_bond = n_bond\n",
        "    self.n_atoms = n_atoms\n",
        "    \n",
        "  #from w to v along e : m_wv\n",
        "  def forward(self, h_w, e_vw):\n",
        "    edge_output = self.fcs.forward(e_vw)\n",
        "    edge_output = edge_output.view(edge_output.size(0), edge_output.size(1), self.n_atoms, self.n_atoms)\n",
        "    h_w = torch.unsqueeze(h_w, 3)\n",
        "    h_multiply =  torch.einsum('ijkk,ijkl->ijkl', [edge_output, h_w])\n",
        "    m_new = torch.squeeze(h_multiply)\n",
        "\n",
        "    return m_new\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGag4Ygei70A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class UpdateFunction(nn.Module):\n",
        "  def __init__(self, n_atoms):\n",
        "    super(UpdateFunction, self).__init__()\n",
        "    self.rnn = nn.GRU(input_size=n_atoms, hidden_size=n_atoms)\n",
        "\n",
        "  def forward(self, h_v, m_v):\n",
        "    m_v = torch.unsqueeze(m_v, 1)\n",
        "    h_v = torch.unsqueeze(h_v, 0)\n",
        "    m_v = m_v.permute(1, 0, 2)\n",
        "    h_v = h_v.contiguous()\n",
        "    m_v = m_v.contiguous()\n",
        "    output, h_n = self.rnn.forward(m_v, h_v)\n",
        "    return h_n.permute(1, 0, 2).squeeze()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDlUlfuqx9Vo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EdgeFunction(nn.Module):\n",
        "  def __init__(self, n_atoms, n_bond):\n",
        "    super(EdgeFunction, self).__init__()\n",
        "    self.rnn = nn.GRU(input_size=n_atoms, hidden_size=n_bond)\n",
        "\n",
        "  def forward(self, e_v, h_v):\n",
        "    e_v = torch.unsqueeze(e_v, 0)\n",
        "    h_v = h_v.permute(1, 0, 2)\n",
        "\n",
        "    h_v = h_v.contiguous()\n",
        "    e_v = e_v.contiguous()\n",
        "    output, h_n = self.rnn.forward(h_v, e_v)\n",
        "    return h_n.permute(1, 0, 2).squeeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MYZMp_UK3Re",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReadoutFunction(nn.Module):\n",
        "  def __init__(self, hidden, node, l_target):\n",
        "    super(ReadoutFunction, self).__init__()\n",
        "\n",
        "    self.hidden = hidden\n",
        "    self.node = node\n",
        "    self.l_target = l_target\n",
        "    # self.i = NNet(n_in=2*hidden, n_out=l_target, hlayers=[128])\n",
        "    # self.j = NNet(n_in=hidden, n_out=l_target, hlayers=[128])\n",
        "\n",
        "    # 1<=M<=12\n",
        "    self.s2s = Set2Set(hidden+node, 6)\n",
        "    self.out = NNet(hidden+node, l_target, hlayers=[128])\n",
        "\n",
        "  def forward(self, h_t, x):\n",
        "      # Equotion 4 in paper\n",
        "      # i_out = nn.Sigmoid()(self.i(torch.cat([h_0, h_t], 2)))\n",
        "      # j_out = self.j(h_t)\n",
        "      # nn_res = i_out * j_out\n",
        "      # ret = torch.sum(nn_res, 1)\n",
        "\n",
        "      # set2set\n",
        "      tup = torch.cat((h_t, x), dim=2)\n",
        "      q_t = self.s2s.forward(tup)\n",
        "      ret = self.out.forward(q_t)\n",
        "\n",
        "      return ret"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk1Kn_xmK6RV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MPNN(nn.Module):\n",
        "  def __init__(self, n_edge_feats, n_node_feats, n_hidden_feats, n_layers=3, n_towers=1,l_target=1):\n",
        "    super(MPNN, self).__init__()\n",
        "    self.m = nn.ModuleList([MessageFunction(n_edge_feats, n_hidden_feats // n_towers) \n",
        "                              for i in range(n_towers)])\n",
        "\n",
        "    self.u = nn.ModuleList([UpdateFunction(n_hidden_feats // n_towers)\n",
        "                              for i in range(n_towers)])\n",
        "\n",
        "    self.r = ReadoutFunction(n_hidden_feats, n_node_feats, l_target)\n",
        "    self.t = NNet(n_in=n_hidden_feats, n_out=n_hidden_feats, hlayers=[128])\n",
        "    #self.t = nn.Linear(n_hidden_feats, n_hidden_feats)\n",
        "    # self.u_e = EdgeFunction(n_hidden_feats, n_edge_feats)\n",
        "\n",
        "    self.n_layers = n_layers\n",
        "    self.l_target = l_target\n",
        "    self.n_edge_feats = n_edge_feats\n",
        "    self.n_node_feats = n_node_feats\n",
        "    self.n_hidden_feats = n_hidden_feats\n",
        "    self.n_towers = n_towers\n",
        "    self.n_div_feats = n_hidden_feats // n_towers\n",
        "\n",
        "    self.emb = nn.Linear(n_node_feats, n_hidden_feats)\n",
        "    self.test = nn.Linear(n_hidden_feats, l_target)\n",
        "\n",
        "  def forward(self, h_in, e):\n",
        "    h = []\n",
        "    h_0 = self.emb(h_in)\n",
        "    h.append(h_0)\n",
        "\n",
        "    for t in range(0, self.n_layers):\n",
        "\n",
        "        h_t = torch.zeros(h_0.size(0), h_0.size(1), h_0.size(2)).cuda()\n",
        "\n",
        "        for v in range(0, h_0.size(1)):\n",
        "            for n in range(self.n_towers):\n",
        "                # Message\n",
        "                m = self.m[n].forward(h[t][:, :, self.n_div_feats*n : self.n_div_feats*(n+1)], \n",
        "                                      e[:, v, :, :])\n",
        "\n",
        "                # Update\n",
        "                h_t[:, v, self.n_div_feats*n : self.n_div_feats*(n+1)] = \n",
        "                      self.u[n].forward(h[t][:, v, self.n_div_feats*n : self.n_div_feats*(n+1)], \n",
        "                                        torch.sum(m,dim=1))\n",
        "        \n",
        "        if(self.n_towers != 1):\n",
        "          h_t = self.t.forward(h_t)\n",
        "        h.append(h_t)\n",
        "\n",
        "    # Readout\n",
        "    res = self.r.forward(h[-1], h_in)\n",
        "    return res \n",
        "\n",
        "            # for e_i in range(0, h_0.size(1)):\n",
        "        #   for e_j in range(0, h_0.size(1)):\n",
        "        #     e[:, e_i, e_j, :] = self.u_e.forward(e[:, e_i, e_j, :], torch.cat((h_t[:, e_i, :].unsqueeze(1), h_t[:, e_j,:].unsqueeze(1)), 1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou7eLpBbMg_8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "64d17ce8-952e-49ae-ff99-81a123e4f0fc"
      },
      "source": [
        "model = MPNN(n_edge_feats=14, n_node_feats=13, n_hidden_feats=64, n_layers=3, n_towers=2, l_target=1)\n",
        "\n",
        "#model = torch.load('/content/gdrive/My Drive/QM9/model_best.pt')\n",
        "\n",
        "epochs = 50\n",
        "\n",
        "\n",
        "# lr = random.uniform(1e-5, 5e-4)\n",
        "lr = 1e-5\n",
        "final = random.uniform(0.01, 1.0)\n",
        "print(lr, final)\n",
        "f_lr = lr * final\n",
        "lr_step = (lr - f_lr) / epochs * 0.8\n",
        "print('Optimizer' , str(lr_step))\n",
        "lambda1 = lambda epoch: lr - (epoch - 0.1*epochs)*lr_step\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.MSELoss()\n",
        "evaluation = lambda output, target: torch.mean(torch.abs(output - target) / torch.abs(target))\n",
        "\n",
        "\n",
        "model = model.cuda()\n",
        "criterion = criterion.cuda()\n",
        "\n",
        "best_er1 = 100\n",
        "\n",
        "train_losses = []\n",
        "train_errs = []\n",
        "valid_losses = []\n",
        "valid_errs = []\n",
        "\n",
        "\n",
        "# Epoch for loop\n",
        "for epoch in range(0, epochs):\n",
        "\n",
        "    # train for one epoch\n",
        "    train_loss, train_err = train(train_loader, model, criterion, optimizer, epoch, evaluation)\n",
        "\n",
        "    \n",
        "    train_losses.append(train_loss)\n",
        "    train_errs.append(train_err)\n",
        "\n",
        "    # evaluate on test set\n",
        "    er1, valid_loss = validate(valid_loader, model, criterion, evaluation)\n",
        "\n",
        "    valid_errs.append(math.log(er1))\n",
        "    valid_losses.append(math.log(valid_loss))\n",
        "\n",
        "\n",
        "    if epoch > epochs * 0.1 and epoch < epochs * 0.9:\n",
        "      lr -= lr_step\n",
        "      for param_group in optimizer.param_groups:\n",
        "          param_group['lr'] = lr\n",
        "\n",
        "    if er1 < best_er1:\n",
        "      best_er1 = er1\n",
        "      print(best_er1, epoch)\n",
        "      torch.save(model, '/content/gdrive/My Drive/QM9/mpnn_model_s2s_tower.pt')\n",
        "    \n",
        "# For testing\n",
        "test_err, _= validate(test_loader, model, criterion, evaluation)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "concat_train_loss = sum(train_losses, [])\n",
        "concat_train_err = sum(train_errs, [])\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 20))\n",
        "plt.subplot(4, 1, 1)\n",
        "plt.plot(concat_train_loss, 'r')\n",
        "plt.title('MPNN')\n",
        "plt.ylabel('Train Loss')\n",
        "\n",
        "plt.subplot(4, 1, 2)\n",
        "plt.plot(concat_train_err, 'g')\n",
        "plt.title('MPNN')\n",
        "plt.ylabel('Train Error')\n",
        "\n",
        "plt.subplot(4, 1, 3)\n",
        "plt.plot(valid_losses, 'b')\n",
        "plt.title('MPNN')\n",
        "plt.ylabel('Valid Loss')\n",
        "\n",
        "plt.subplot(4, 1, 4)\n",
        "plt.plot(valid_errs, 'm')\n",
        "plt.title('MPNN')\n",
        "plt.ylabel('Valid Error')\n",
        "plt.xlabel('Num iteration')\n",
        "\n",
        "print(test_err)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1e-05 0.06573543802155697\n",
            "Optimizer 1.4948232991655092e-07\n",
            "outputs :  tensor([-0.0243], device='cuda:0', grad_fn=<SelectBackward>) tensor([-0.6858], device='cuda:0')\n",
            "Epoch: [0][0/885]\tTime 1.675 (1.675)\tData 0.015 (0.015)\tLoss 0.9412 (0.9412)\tError Ratio 1.0003 (1.0003)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnoZHO_1jkE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(test_err)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VoX1FjuZ9BM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YXfOOk7wgjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}